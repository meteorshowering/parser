{"type": "footer", "bbox": [1206, 2973, 1243, 3001], "res": [{"text": "18", "confidence": 0.9996968507766724, "text_region": [[1201.0, 2970.0], [1254.0, 2970.0], [1254.0, 3013.0], [1201.0, 3013.0]]}], "img_idx": 0, "score": 0.894769549369812}
{"type": "reference", "bbox": [436, 299, 2021, 2890], "res": [{"text": "[18] E. Frantar, S. Ashkboos, T. Hoefer, and D. Alistarh. Gptq: Accurate post-training quantization", "confidence": 0.986017644405365, "text_region": [[422.0, 290.0], [2022.0, 294.0], [2022.0, 350.0], [422.0, 346.0]]}, {"text": "for generative pre-trained transformers. arXiv preprint arXiv:2210.17323, 2022.", "confidence": 0.9939622282981873, "text_region": [[519.0, 343.0], [1799.0, 343.0], [1799.0, 389.0], [519.0, 389.0]]}, {"text": "[19] J. Fu, S.-K. Ng, Z. Jiang, and P. Liu. Gptscore: Evaluate as you desire. arXiv preprint", "confidence": 0.9882594347000122, "text_region": [[426.0, 416.0], [2019.0, 419.0], [2019.0, 465.0], [426.0, 462.0]]}, {"text": "arXiv:2302.04166, 2023.", "confidence": 0.9990645051002502, "text_region": [[516.0, 462.0], [918.0, 462.0], [918.0, 505.0], [516.0, 505.0]]}, {"text": "[20] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, and D. Song. Koala: A", "confidence": 0.996299684047699, "text_region": [[429.0, 538.0], [2019.0, 538.0], [2019.0, 584.0], [429.0, 584.0]]}, {"text": " dialogue model for academic research. Blog post, April 2023. URL https : / /bair . berkeley.", "confidence": 0.9627053141593933, "text_region": [[509.0, 574.0], [2022.0, 574.0], [2022.0, 630.0], [509.0, 630.0]]}, {"text": "edu/blog/2023/04/03/k0ala/.", "confidence": 0.957177460193634, "text_region": [[519.0, 627.0], [1068.0, 627.0], [1068.0, 670.0], [519.0, 670.0]]}, {"text": "[21] A. Glaese, N. McAleese, M. Trebacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger,", "confidence": 0.9866504073143005, "text_region": [[432.0, 700.0], [2019.0, 700.0], [2019.0, 746.0], [432.0, 746.0]]}, {"text": "M. Chadwick, P. Thacker, et al. Improving alignment of dialogue agents via targeted human", "confidence": 0.9852300882339478, "text_region": [[509.0, 739.0], [2022.0, 743.0], [2022.0, 799.0], [509.0, 795.0]]}, {"text": "judgements. arXiv preprint arXiv:2209.14375, 2022.", "confidence": 0.9992751479148865, "text_region": [[512.0, 789.0], [1364.0, 785.0], [1364.0, 832.0], [512.0, 835.0]]}, {"text": "[22] S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. R. Bowman, and N. A. Smith", "confidence": 0.9815054535865784, "text_region": [[429.0, 865.0], [2016.0, 865.0], [2016.0, 911.0], [429.0, 911.0]]}, {"text": "Annotation artifacts in natural language inference data. arXiv preprint arXiv: 1803.02324, 2018.", "confidence": 0.9904664158821106, "text_region": [[516.0, 911.0], [2019.0, 911.0], [2019.0, 957.0], [516.0, 957.0]]}, {"text": "[23]  J. Henderson, S. Ruder, et al. Compacter: Efficient low-rank hypercomplex adapter layers. In", "confidence": 0.972704291343689, "text_region": [[432.0, 987.0], [2019.0, 987.0], [2019.0, 1033.0], [432.0, 1033.0]]}, {"text": "Advances in Neural Information Processing Systems, 2021.", "confidence": 0.9908650517463684, "text_region": [[512.0, 1033.0], [1463.0, 1033.0], [1463.0, 1076.0], [512.0, 1076.0]]}, {"text": "[24] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Mea-", "confidence": 0.9906588792800903, "text_region": [[429.0, 1102.0], [2019.0, 1106.0], [2019.0, 1152.0], [429.0, 1148.0]]}, {"text": "suring massive multitask language understanding. In International Conference on Learning", "confidence": 0.9970592856407166, "text_region": [[516.0, 1148.0], [2022.0, 1148.0], [2022.0, 1204.0], [516.0, 1204.0]]}, {"text": "Representations, 2020.", "confidence": 0.9994266033172607, "text_region": [[516.0, 1195.0], [885.0, 1195.0], [885.0, 1241.0], [516.0, 1241.0]]}, {"text": "[25] A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi. The curious case of neural text", "confidence": 0.9850382208824158, "text_region": [[432.0, 1270.0], [2019.0, 1270.0], [2019.0, 1317.0], [432.0, 1317.0]]}, {"text": "degeneration. In International Conference on Learning Representations, 2020.", "confidence": 0.9964460134506226, "text_region": [[512.0, 1313.0], [1773.0, 1310.0], [1773.0, 1356.0], [512.0, 1360.0]]}, {"text": "[26] O. Honovich, T. Scialom, O. Levy, and T. Schick. Unnatural instructions: Tuning language", "confidence": 0.9935727715492249, "text_region": [[422.0, 1383.0], [2022.0, 1386.0], [2022.0, 1442.0], [422.0, 1439.0]]}, {"text": "models with (almost) no human labor. arXiv preprint arXiv:2212.09689, 2022.", "confidence": 0.9961064457893372, "text_region": [[516.0, 1436.0], [1776.0, 1436.0], [1776.0, 1482.0], [516.0, 1482.0]]}, {"text": "[27] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. At-", "confidence": 0.9872661232948303, "text_region": [[432.0, 1508.0], [2022.0, 1508.0], [2022.0, 1554.0], [432.0, 1554.0]]}, {"text": "tariyan, and S. Gelly. Parameter-efficient transfer learning for nlp. In International Conference", "confidence": 0.9828245043754578, "text_region": [[512.0, 1551.0], [2019.0, 1554.0], [2019.0, 1601.0], [512.0, 1597.0]]}, {"text": "on Machine Learning, pages 2790-2799. PMLR, 2019.", "confidence": 0.9877439737319946, "text_region": [[516.0, 1594.0], [1407.0, 1594.0], [1407.0, 1650.0], [516.0, 1650.0]]}, {"text": "[28] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora:", "confidence": 0.985810399055481, "text_region": [[429.0, 1673.0], [2019.0, 1673.0], [2019.0, 1719.0], [429.0, 1719.0]]}, {"text": "Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.", "confidence": 0.9843347668647766, "text_region": [[512.0, 1713.0], [1929.0, 1709.0], [1929.0, 1765.0], [512.0, 1769.0]]}, {"text": "[29] S. Iyer, X. V. Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S", "confidence": 0.9906057119369507, "text_region": [[429.0, 1789.0], [2012.0, 1789.0], [2012.0, 1835.0], [429.0, 1835.0]]}, {"text": "Koura, et al. Opt-iml: Scaling language model instruction meta learning through the lens of", "confidence": 0.9987969994544983, "text_region": [[516.0, 1838.0], [2019.0, 1838.0], [2019.0, 1884.0], [516.0, 1884.0]]}, {"text": "generalization. arXiv preprint arXiv:2212.12017, 2022.", "confidence": 0.9951492547988892, "text_region": [[519.0, 1881.0], [1410.0, 1881.0], [1410.0, 1927.0], [519.0, 1927.0]]}, {"text": "[30] A. Koksal, T. Schick, A. Korhonen, and H. Schitze. Longform: Optimizing instruction tuning", "confidence": 0.9755441546440125, "text_region": [[426.0, 1954.0], [2019.0, 1957.0], [2019.0, 2003.0], [426.0, 2000.0]]}, {"text": "for long text generation with corpus extraction. arXiv preprint arXiv:2304.08460, 2023.", "confidence": 0.9974821209907532, "text_region": [[512.0, 2000.0], [1919.0, 1996.0], [1919.0, 2043.0], [512.0, 2046.0]]}, {"text": "[31] A. Kopf, Y. Kilcher, D. von Ritte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M.", "confidence": 0.9817214608192444, "text_region": [[426.0, 2072.0], [2022.0, 2072.0], [2022.0, 2128.0], [426.0, 2128.0]]}, {"text": " Duc, O. Stanley, R. Nagyfi, et al. Openassistant conversations-democratizing large language", "confidence": 0.9856666326522827, "text_region": [[509.0, 2112.0], [2022.0, 2119.0], [2022.0, 2175.0], [509.0, 2168.0]]}, {"text": "model alignment. arXiv preprint arXiv:2304.07327, 2023.", "confidence": 0.999430775642395, "text_region": [[519.0, 2165.0], [1450.0, 2165.0], [1450.0, 2211.0], [519.0, 2211.0]]}, {"text": "[32]  LAION. (", "confidence": 0.861949622631073, "text_region": [[429.0, 2237.0], [755.0, 2237.0], [755.0, 2284.0], [429.0, 2284.0]]}, {"text": " Open-instruction-generalist  dataset.", "confidence": 0.9651767611503601, "text_region": [[735.0, 2241.0], [1350.0, 2241.0], [1350.0, 2287.0], [735.0, 2287.0]]}, {"text": "https://github.com/LAION-AI/", "confidence": 0.9972667098045349, "text_region": [[1423.0, 2241.0], [2019.0, 2237.0], [2019.0, 2284.0], [1424.0, 2287.0]]}, {"text": "Open-Instruction-Generalist, 2023.", "confidence": 0.9948392510414124, "text_region": [[512.0, 2284.0], [1194.0, 2280.0], [1194.0, 2326.0], [512.0, 2330.0]]}, {"text": "[33] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for parameter-efficient prompt", "confidence": 0.9908159971237183, "text_region": [[426.0, 2356.0], [2019.0, 2363.0], [2019.0, 2406.0], [426.0, 2399.0]]}, {"text": "tuning. arXiv preprint arXiv:2104.08691, 2021.", "confidence": 0.9974994659423828, "text_region": [[516.0, 2406.0], [1287.0, 2406.0], [1287.0, 2452.0], [516.0, 2452.0]]}, {"text": "[34] X. L. Li and P. Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv", "confidence": 0.9919299483299255, "text_region": [[422.0, 2472.0], [2022.0, 2475.0], [2022.0, 2531.0], [422.0, 2528.0]]}, {"text": "preprint arXiv:2101.00190, 2021.", "confidence": 0.9960399866104126, "text_region": [[512.0, 2525.0], [1054.0, 2521.0], [1054.0, 2567.0], [512.0, 2571.0]]}, {"text": "[35] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan,", "confidence": 0.99561607837677, "text_region": [[432.0, 2600.0], [2019.0, 2600.0], [2019.0, 2647.0], [432.0, 2647.0]]}, {"text": "Y. Wu, A. Kumar, et al.  Holistic evaluation of language models.  arXiv preprint", "confidence": 0.9699079394340515, "text_region": [[509.0, 2637.0], [2022.0, 2640.0], [2022.0, 2696.0], [509.0, 2693.0]]}, {"text": "arXiv:2211.09110, 2022.", "confidence": 0.9990437626838684, "text_region": [[512.0, 2686.0], [915.0, 2686.0], [915.0, 2729.0], [512.0, 2729.0]]}, {"text": "[36] T. Liao, R. Taori, I. D. Raji, and L. Schmidt. Are we learning yet? a meta review of evaluation", "confidence": 0.9932800531387329, "text_region": [[426.0, 2759.0], [2019.0, 2759.0], [2019.0, 2815.0], [426.0, 2815.0]]}, {"text": "failures across machine learning. In Thirty-fifth Conference on Neural Information Processing", "confidence": 0.9880192279815674, "text_region": [[516.0, 2802.0], [2019.0, 2808.0], [2019.0, 2855.0], [515.0, 2848.0]]}, {"text": "Systems Datasets and Benchmarks Track (Round 2), 2021.", "confidence": 0.9758573174476624, "text_region": [[519.0, 2854.0], [1444.0, 2854.0], [1444.0, 2897.0], [519.0, 2897.0]]}], "img_idx": 0, "score": 0.9865977168083191}
