{"type": "text", "bbox": [428, 695, 2017, 2015], "res": [{"text": "Evaluation We report moderate agreement among human annotators (Fleiss K = 0.42) with", "confidence": 0.9782297611236572, "text_region": [[429.0, 696.0], [2019.0, 696.0], [2019.0, 742.0], [429.0, 742.0]]}, {"text": "additional deterioration when comparing two strong systems. This points to limitations in the", "confidence": 0.9906027913093567, "text_region": [[429.0, 742.0], [2019.0, 742.0], [2019.0, 789.0], [429.0, 789.0]]}, {"text": "current benchmarks and human evaluation protocols for chatbot task performance. When manually", "confidence": 0.9945042133331299, "text_region": [[432.0, 785.0], [2019.0, 785.0], [2019.0, 832.0], [432.0, 832.0]]}, {"text": "comparing generations from ChatGPT and Guanaco 65B on the Vicuna benchmark, we find that", "confidence": 0.9882425665855408, "text_region": [[432.0, 828.0], [2019.0, 828.0], [2019.0, 874.0], [432.0, 874.0]]}, {"text": " subjective preferences start to play an important role as the authors of this paper disagreed on the", "confidence": 0.9803076386451721, "text_region": [[422.0, 868.0], [2022.0, 865.0], [2022.0, 921.0], [422.0, 924.0]]}, {"text": "many preferred responses. Future work should investigate approaches to mitigate these problems", "confidence": 0.9878817796707153, "text_region": [[429.0, 917.0], [2019.0, 917.0], [2019.0, 960.0], [429.0, 960.0]]}, {"text": "drawing from disciplines that developed mechanisms to deal with subjective preferences, such as", "confidence": 0.9949798583984375, "text_region": [[429.0, 960.0], [2019.0, 960.0], [2019.0, 1006.0], [429.0, 1006.0]]}, {"text": " Human-Computer Interaction and Psychology.", "confidence": 0.9771991968154907, "text_region": [[419.0, 997.0], [1178.0, 1000.0], [1177.0, 1056.0], [419.0, 1053.0]]}, {"text": "In our analysis, we also find that automated evaluation systems have noticeable biases. For example,", "confidence": 0.9922657608985901, "text_region": [[426.0, 1069.0], [2019.0, 1069.0], [2019.0, 1112.0], [426.0, 1112.0]]}, {"text": "we observe strong order effects with GPT-4 assigning higher scores to the system appearing first in its", "confidence": 0.9810819029808044, "text_region": [[422.0, 1105.0], [2022.0, 1109.0], [2022.0, 1165.0], [422.0, 1162.0]]}, {"text": "prompt. The relatively weak sample-level agreement between GPT-4 and human annotators (Fleiss", "confidence": 0.9933183789253235, "text_region": [[426.0, 1158.0], [2019.0, 1155.0], [2019.0, 1201.0], [426.0, 1205.0]]}, {"text": "K = 0.25) also suggests that human annotators and automated systems might rely on preferences", "confidence": 0.9921513795852661, "text_region": [[429.0, 1201.0], [2019.0, 1201.0], [2019.0, 1247.0], [429.0, 1247.0]]}, {"text": "that are not always aligned. In addition, in Table 7, we observe that GPT-4 assigns significantly", "confidence": 0.9958434700965881, "text_region": [[429.0, 1244.0], [2019.0, 1244.0], [2019.0, 1290.0], [429.0, 1290.0]]}, {"text": "higher scores to its own outputs compared to human ratings, Elo of 1348 vs 1176, which represent an", "confidence": 0.9882644414901733, "text_region": [[429.0, 1287.0], [2019.0, 1287.0], [2019.0, 1333.0], [429.0, 1333.0]]}, {"text": "additional 20% probability of winning against an opponent. Future work should examine the presence", "confidence": 0.9864787459373474, "text_region": [[429.0, 1333.0], [2019.0, 1333.0], [2019.0, 1379.0], [429.0, 1379.0]]}, {"text": "of potential biases in automated evaluation systems as well as possible mitigation strategies.", "confidence": 0.9939916729927063, "text_region": [[426.0, 1376.0], [1899.0, 1376.0], [1899.0, 1422.0], [426.0, 1422.0]]}, {"text": "Data & Training We note that the OASST1 dataset on which Guanaco models are trained is", "confidence": 0.9809964895248413, "text_region": [[429.0, 1445.0], [2019.0, 1445.0], [2019.0, 1492.0], [429.0, 1492.0]]}, {"text": "multilingual and that the OA benchmark also contains prompts in different languages. We leave it to", "confidence": 0.9959625005722046, "text_region": [[429.0, 1492.0], [2019.0, 1492.0], [2019.0, 1538.0], [429.0, 1538.0]]}, {"text": "future work to investigate the degree to which such multilingual training improves performance on", "confidence": 0.9944067001342773, "text_region": [[429.0, 1534.0], [2019.0, 1534.0], [2019.0, 1581.0], [429.0, 1581.0]]}, {"text": " instructions in languages other than English and whether this explains the larger gap between Vicuna-", "confidence": 0.9836713671684265, "text_region": [[422.0, 1574.0], [2022.0, 1571.0], [2022.0, 1627.0], [422.0, 1630.0]]}, {"text": "13B model (only trained on English data) and Guanaco 33B and 65B on the OA benchmark.", "confidence": 0.9978999495506287, "text_region": [[429.0, 1620.0], [1899.0, 1620.0], [1899.0, 1667.0], [429.0, 1667.0]]}, {"text": "Given the strong performance of Guanaco models, we investigate any data leakage between the", "confidence": 0.9895250201225281, "text_region": [[426.0, 1680.0], [2022.0, 1683.0], [2022.0, 1739.0], [426.0, 1736.0]]}, {"text": "OASST1 data and the Vicuna benchmark prompts. We do not find overlapping prompts after perform-", "confidence": 0.9848570823669434, "text_region": [[429.0, 1729.0], [2026.0, 1729.0], [2026.0, 1785.0], [429.0, 1785.0]]}, {"text": "ing fuzzy string matching in the two datasets and inspecting the closest matches manually.", "confidence": 0.9885942339897156, "text_region": [[426.0, 1775.0], [1869.0, 1775.0], [1869.0, 1822.0], [426.0, 1822.0]]}, {"text": "Furthermore, we note that our model is only trained with cross-entropy loss (supervised learning)", "confidence": 0.9899610280990601, "text_region": [[426.0, 1838.0], [2016.0, 1838.0], [2016.0, 1884.0], [426.0, 1884.0]]}, {"text": "without relying on reinforcement learning from human feedback (RLHF). This calls for further", "confidence": 0.987998366355896, "text_region": [[429.0, 1888.0], [2016.0, 1888.0], [2016.0, 1934.0], [429.0, 1934.0]]}, {"text": "investigations of the tradeoffs of simple cross-entropy loss and RLHF training. We hope that QLoRA", "confidence": 0.9826619029045105, "text_region": [[429.0, 1930.0], [2019.0, 1930.0], [2019.0, 1977.0], [429.0, 1977.0]]}, {"text": "enables such analysis at scale, without the need for overwhelming computational resources.", "confidence": 0.9934555292129517, "text_region": [[426.0, 1973.0], [1893.0, 1973.0], [1893.0, 2020.0], [426.0, 2020.0]]}], "img_idx": 0, "score": 0.9897443056106567}
{"type": "text", "bbox": [428, 2141, 2019, 2438], "res": [{"text": "Quantization of Large Language Models Quantization of LLMs has largely focused on quanti-", "confidence": 0.9774097800254822, "text_region": [[426.0, 2132.0], [2022.0, 2132.0], [2022.0, 2188.0], [426.0, 2188.0]]}, {"text": "zation for inference time. Major approaches for preserving 16-bit LLM quality focus on managing", "confidence": 0.9791236519813538, "text_region": [[422.0, 2171.0], [2026.0, 2171.0], [2026.0, 2237.0], [422.0, 2237.0]]}, {"text": "outlier features (e.g., SmoothQuant [66] and LLM.int8O [14]) while others use more sophisticated", "confidence": 0.9915361404418945, "text_region": [[429.0, 2224.0], [2019.0, 2224.0], [2019.0, 2270.0], [429.0, 2270.0]]}, {"text": "grouping methods [44, 69]. Lossy quantization approaches study the trade-offs for regular round.", "confidence": 0.9920854568481445, "text_region": [[426.0, 2267.0], [2016.0, 2267.0], [2016.0, 2313.0], [426.0, 2313.0]]}, {"text": "ing [13, 71, 47] or how to optimize rounding decisions to improve quantization precision [18].", "confidence": 0.9900084733963013, "text_region": [[429.0, 2313.0], [2022.0, 2313.0], [2022.0, 2360.0], [429.0, 2360.0]]}, {"text": " Besides our work, SwitchBack layers [65] is the only work that studies backpropagation through", "confidence": 0.9846633076667786, "text_region": [[422.0, 2346.0], [2022.0, 2350.0], [2022.0, 2406.0], [422.0, 2402.0]]}, {"text": "quantized weights at a scale beyond 1B parameters.", "confidence": 0.9964749813079834, "text_region": [[429.0, 2402.0], [1254.0, 2402.0], [1254.0, 2445.0], [429.0, 2445.0]]}], "img_idx": 0, "score": 0.9777028560638428}
{"type": "text", "bbox": [429, 2472, 2015, 2903], "res": [{"text": "Finetuning with Adapters  While we use Low-rank Adapters [28] (LoRA), many other Parameter", "confidence": 0.9806930422782898, "text_region": [[429.0, 2472.0], [2019.0, 2472.0], [2019.0, 2515.0], [429.0, 2515.0]]}, {"text": " Effcient FineTuning (PEFT) methods have been proposed such as prompt tuning [48, 33, 34], tuning", "confidence": 0.980763852596283, "text_region": [[423.0, 2505.0], [2026.0, 2511.0], [2025.0, 2567.0], [422.0, 2561.0]]}, {"text": "the embedding layer inputs [1], tuning hidden states (IA?) [37], adding full layers [27], tuning", "confidence": 0.9889234900474548, "text_region": [[426.0, 2557.0], [2022.0, 2561.0], [2022.0, 2607.0], [426.0, 2604.0]]}, {"text": "biases [70], learning a mask over weights based on Fisher information [54], and a combination of", "confidence": 0.9920037388801575, "text_region": [[426.0, 2597.0], [2019.0, 2600.0], [2019.0, 2647.0], [426.0, 2643.0]]}, {"text": "approaches [23]. In our work, we show that LoRA adapters are able to reach full 16-bit finetuning", "confidence": 0.9863547086715698, "text_region": [[426.0, 2643.0], [2026.0, 2643.0], [2026.0, 2699.0], [426.0, 2699.0]]}, {"text": "performance. We leave it to future work to explore the tradeoffs of other PEFT approaches", "confidence": 0.9962934255599976, "text_region": [[426.0, 2690.0], [1879.0, 2690.0], [1879.0, 2736.0], [426.0, 2736.0]]}, {"text": "Instruction Finetuning  To help a pretrained LLM follow the instructions provided in a prompt,", "confidence": 0.9863166809082031, "text_region": [[426.0, 2762.0], [2019.0, 2762.0], [2019.0, 2808.0], [426.0, 2808.0]]}, {"text": "instruction finetuning uses input-output pairs of various data sources to finetune a pretrained LLM", "confidence": 0.9986093640327454, "text_region": [[426.0, 2805.0], [2019.0, 2805.0], [2019.0, 2851.0], [426.0, 2851.0]]}, {"text": "to generate the output given the input as a prompt. Approaches and datasets include MetaICL [40],", "confidence": 0.9882131218910217, "text_region": [[426.0, 2851.0], [2022.0, 2848.0], [2022.0, 2894.0], [426.0, 2897.0]]}], "img_idx": 0, "score": 0.9713524580001831}
{"type": "text", "bbox": [432, 299, 1917, 600], "res": [{"text": "playroom. Jackson moved the beans to the pantry. Jackson exited the playroom.", "confidence": 0.9878348112106323, "text_region": [[572.0, 297.0], [1879.0, 297.0], [1879.0, 343.0], [572.0, 343.0]]}, {"text": "James entered the living room. Where will James look for the beans?", "confidence": 0.9801768064498901, "text_region": [[572.0, 340.0], [1683.0, 340.0], [1683.0, 386.0], [572.0, 386.0]]}, {"text": "Guanaco: James will look for the beans in the pantry, because", "confidence": 0.9715995192527771, "text_region": [[569.0, 403.0], [1876.0, 409.0], [1876.0, 455.0], [569.0, 449.0]]}, {"text": "that's where Jackson moved them.", "confidence": 0.993160605430603, "text_region": [[572.0, 449.0], [1241.0, 452.0], [1240.0, 498.0], [572.0, 495.0]]}, {"text": "where Guanaco presumes information transfer that was never described. These issues echo recent", "confidence": 0.9853205680847168, "text_region": [[422.0, 512.0], [2022.0, 508.0], [2022.0, 564.0], [422.0, 568.0]]}, {"text": "literature [51], but require more study.", "confidence": 0.9822149276733398, "text_region": [[426.0, 561.0], [1041.0, 561.0], [1041.0, 607.0], [426.0, 607.0]]}], "img_idx": 0, "score": 0.9487124085426331}
{"type": "title", "bbox": [432, 2062, 788, 2098], "res": [{"text": "7Related Work", "confidence": 0.9972298741340637, "text_region": [[426.0, 2059.0], [792.0, 2059.0], [792.0, 2105.0], [426.0, 2105.0]]}], "img_idx": 0, "score": 0.9558207392692566}
{"type": "title", "bbox": [431, 641, 778, 671], "res": [{"text": "6.2 Considerations", "confidence": 0.9772765636444092, "text_region": [[426.0, 633.0], [782.0, 637.0], [781.0, 683.0], [426.0, 680.0]]}], "img_idx": 0, "score": 0.9507164359092712}
{"type": "footer", "bbox": [1207, 2974, 1245, 3000], "res": [{"text": "14", "confidence": 0.9997684955596924, "text_region": [[1201.0, 2970.0], [1254.0, 2970.0], [1254.0, 3010.0], [1201.0, 3010.0]]}], "img_idx": 0, "score": 0.891415536403656}
