{"type": "figure", "bbox": [232, 256, 2149, 2667], "res": [{"text": "158", "confidence": 0.9961352944374084, "text_region": [[1274.0, 2244.0], [1344.0, 2244.0], [1344.0, 2290.0], [1274.0, 2290.0]]}], "img_idx": 0, "score": 0.9685061573982239}
{"type": "figure_caption", "bbox": [325, 2709, 2122, 2874], "res": [{"text": "Figure 21. Visualization of predictions from 36 CLIP zero-shot classifiers. All examples are random with the exception of reselecting", "confidence": 0.9934625625610352, "text_region": [[220.0, 2703.0], [2169.0, 2703.0], [2169.0, 2749.0], [220.0, 2749.0]]}, {"text": "Hateful Memes to avoid offensive content. The predicted probability of the top 5 classes is shown along with the text used to represent", "confidence": 0.9970022439956665, "text_region": [[216.0, 2742.0], [2169.0, 2746.0], [2169.0, 2792.0], [216.0, 2788.0]]}, {"text": "the class. When more than one template is used, the first template is shown. The ground truth label is colored green while an incorrect", "confidence": 0.9913250803947449, "text_region": [[216.0, 2792.0], [2172.0, 2792.0], [2172.0, 2838.0], [216.0, 2838.0]]}, {"text": "prediction is colored orange.", "confidence": 0.9925819039344788, "text_region": [[216.0, 2835.0], [635.0, 2835.0], [635.0, 2881.0], [216.0, 2881.0]]}], "img_idx": 0, "score": 0.9040601253509521}
{"type": "header", "bbox": [2125, 191, 2164, 217], "res": [{"text": "42", "confidence": 0.9991034865379333, "text_region": [[2129.0, 191.0], [2162.0, 191.0], [2162.0, 221.0], [2129.0, 221.0]]}], "img_idx": 0, "score": 0.8908191919326782}
{"type": "header", "bbox": [421, 193, 1318, 224], "res": [{"text": "Learning Transferable Visual Models From Natural Language Supervision", "confidence": 0.9942678809165955, "text_region": [[220.0, 188.0], [1370.0, 188.0], [1370.0, 231.0], [220.0, 231.0]]}], "img_idx": 0, "score": 0.6608586311340332}
