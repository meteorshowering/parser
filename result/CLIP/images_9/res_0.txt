{"type": "text", "bbox": [220, 2092, 1161, 2871], "res": [{"text": "If we assume that evaluation datasets are large enough that", "confidence": 0.9912844300270081, "text_region": [[216.0, 2082.0], [1161.0, 2082.0], [1161.0, 2128.0], [216.0, 2128.0]]}, {"text": "the parameters of linear classifiers trained on them are well", "confidence": 0.9849894642829895, "text_region": [[220.0, 2135.0], [1164.0, 2135.0], [1164.0, 2181.0], [220.0, 2181.0]]}, {"text": "estimated, then, because CLIP's zero-shot classifier is also", "confidence": 0.9940339922904968, "text_region": [[216.0, 2181.0], [1164.0, 2181.0], [1164.0, 2224.0], [216.0, 2224.0]]}, {"text": " a linear classifier, the performance of the fully supervised", "confidence": 0.9913651943206787, "text_region": [[210.0, 2221.0], [1164.0, 2224.0], [1164.0, 2280.0], [209.0, 2277.0]]}, {"text": "classifiers roughly sets an upper bound for what zero-shot", "confidence": 0.9954649806022644, "text_region": [[213.0, 2274.0], [1171.0, 2274.0], [1171.0, 2330.0], [213.0, 2330.0]]}, {"text": "transfer can achieve. In Figure 8 we compare CLIP's zero-", "confidence": 0.9945176243782043, "text_region": [[216.0, 2326.0], [1167.0, 2326.0], [1167.0, 2373.0], [216.0, 2373.0]]}, {"text": "shot performance with fully supervised linear classifiers", "confidence": 0.9907253384590149, "text_region": [[216.0, 2369.0], [1164.0, 2369.0], [1164.0, 2426.0], [216.0, 2426.0]]}, {"text": "across datasets. The dashed, y =  line represents an \u201cop-", "confidence": 0.9966033697128296, "text_region": [[216.0, 2422.0], [1161.0, 2422.0], [1161.0, 2468.0], [216.0, 2468.0]]}, {"text": "timal\u2019 zero-shot classifier that matches the performance of", "confidence": 0.9710246324539185, "text_region": [[216.0, 2468.0], [1164.0, 2468.0], [1164.0, 2515.0], [216.0, 2515.0]]}, {"text": "its fully supervised equivalent. For most datasets, the per-", "confidence": 0.9861800670623779, "text_region": [[220.0, 2515.0], [1164.0, 2515.0], [1164.0, 2561.0], [220.0, 2561.0]]}, {"text": "formance of zero-shot classifiers still underperform fully su-", "confidence": 0.9841724038124084, "text_region": [[216.0, 2567.0], [1167.0, 2567.0], [1167.0, 2610.0], [216.0, 2610.0]]}, {"text": "pervised classifiers by 10% to 25%, suggesting that there is", "confidence": 0.9981634616851807, "text_region": [[216.0, 2614.0], [1164.0, 2614.0], [1164.0, 2660.0], [216.0, 2660.0]]}, {"text": " still plenty of headroom for improving CLIP's task-learning", "confidence": 0.9864855408668518, "text_region": [[210.0, 2653.0], [1168.0, 2657.0], [1167.0, 2713.0], [209.0, 2709.0]]}, {"text": "and zero-shot transfer capabilities.", "confidence": 0.996373176574707, "text_region": [[216.0, 2709.0], [772.0, 2709.0], [772.0, 2752.0], [216.0, 2752.0]]}, {"text": "There is a positive correlation of 0.82 (p-value < 10-6)", "confidence": 0.9878925681114197, "text_region": [[209.0, 2775.0], [1170.0, 2769.0], [1171.0, 2828.0], [210.0, 2835.0]]}, {"text": "between zero-shot performance and fully supervised perfor-", "confidence": 0.9991807341575623, "text_region": [[216.0, 2828.0], [1164.0, 2828.0], [1164.0, 2874.0], [216.0, 2874.0]]}], "img_idx": 0, "score": 0.9939079284667969}
{"type": "text", "bbox": [1227, 2214, 2168, 2862], "res": [{"text": " Over the past few years, empirical studies of deep learning", "confidence": 0.9915800094604492, "text_region": [[1221.0, 2198.0], [2175.0, 2201.0], [2175.0, 2257.0], [1221.0, 2254.0]]}, {"text": "systems have documented that performance is predictable as", "confidence": 0.9840019941329956, "text_region": [[1227.0, 2254.0], [2172.0, 2254.0], [2172.0, 2300.0], [1227.0, 2300.0]]}, {"text": "a function of important quantities such as training compute", "confidence": 0.9896561503410339, "text_region": [[1224.0, 2303.0], [2172.0, 2303.0], [2172.0, 2350.0], [1224.0, 2350.0]]}, {"text": "and dataset size (Hestness et al., 2017; Kaplan et al., 2020).", "confidence": 0.9942180514335632, "text_region": [[1224.0, 2350.0], [2175.0, 2350.0], [2175.0, 2392.0], [1224.0, 2392.0]]}, {"text": "The GPT family of models has so far demonstrated consis-", "confidence": 0.9863254427909851, "text_region": [[1224.0, 2396.0], [2172.0, 2396.0], [2172.0, 2442.0], [1224.0, 2442.0]]}, {"text": "tent improvements in zero-shot performance across a 1000x", "confidence": 0.9992423057556152, "text_region": [[1221.0, 2445.0], [2172.0, 2442.0], [2172.0, 2488.0], [1221.0, 2492.0]]}, {"text": " increase in training compute. In Figure 9, we check whether", "confidence": 0.9934594035148621, "text_region": [[1217.0, 2485.0], [2175.0, 2488.0], [2175.0, 2544.0], [1217.0, 2541.0]]}, {"text": "the zero-shot performance of CLIP follows a similar scaling", "confidence": 0.9951105713844299, "text_region": [[1224.0, 2541.0], [2172.0, 2541.0], [2172.0, 2587.0], [1224.0, 2587.0]]}, {"text": " pattern. We plot the average error rate of the 5 ResNet CLIP", "confidence": 0.985755205154419, "text_region": [[1217.0, 2584.0], [2175.0, 2581.0], [2175.0, 2637.0], [1217.0, 2640.0]]}, {"text": " models across 39 evaluations on 36 different datasets and", "confidence": 0.9783467650413513, "text_region": [[1221.0, 2637.0], [2172.0, 2633.0], [2172.0, 2680.0], [1221.0, 2683.0]]}, {"text": "find that a similar log-log linear scaling trend holds for CLIP", "confidence": 0.9859462976455688, "text_region": [[1224.0, 2683.0], [2172.0, 2683.0], [2172.0, 2729.0], [1224.0, 2729.0]]}, {"text": "across a 44x increase in model compute. While the overall", "confidence": 0.9986722469329834, "text_region": [[1224.0, 2732.0], [2172.0, 2732.0], [2172.0, 2779.0], [1224.0, 2779.0]]}, {"text": "trend is smooth, we found that performance on individual", "confidence": 0.9882130026817322, "text_region": [[1221.0, 2779.0], [2169.0, 2779.0], [2169.0, 2825.0], [1221.0, 2825.0]]}, {"text": "evaluations can be much noisier. We are unsure whether", "confidence": 0.9987598657608032, "text_region": [[1224.0, 2828.0], [2172.0, 2828.0], [2172.0, 2874.0], [1224.0, 2874.0]]}], "img_idx": 0, "score": 0.993414044380188}
{"type": "text", "bbox": [1227, 1468, 2168, 2166], "res": [{"text": " mance, suggesting that CLIP is relatively consistent at con-", "confidence": 0.9904279112815857, "text_region": [[1221.0, 1465.0], [2172.0, 1462.0], [2172.0, 1508.0], [1221.0, 1511.0]]}, {"text": "necting underlying representation and task learning to zero-", "confidence": 0.986437201499939, "text_region": [[1224.0, 1508.0], [2179.0, 1508.0], [2179.0, 1564.0], [1224.0, 1564.0]]}, {"text": "shot transfer. However, zero-shot CLIP only approaches", "confidence": 0.9994644522666931, "text_region": [[1224.0, 1561.0], [2172.0, 1561.0], [2172.0, 1607.0], [1224.0, 1607.0]]}, {"text": "fully supervised performance on 5 datasets: STL10, CI-", "confidence": 0.997223973274231, "text_region": [[1224.0, 1607.0], [2175.0, 1607.0], [2175.0, 1653.0], [1224.0, 1653.0]]}, {"text": "FAR10, Food101, OxfordPets, and Caltech101. On all 5", "confidence": 0.9958801865577698, "text_region": [[1224.0, 1657.0], [2172.0, 1657.0], [2172.0, 1699.0], [1224.0, 1699.0]]}, {"text": "datasets, both zero-shot accuracy and fully supervised accu-", "confidence": 0.9984161257743835, "text_region": [[1224.0, 1703.0], [2175.0, 1703.0], [2175.0, 1749.0], [1224.0, 1749.0]]}, {"text": "racy are over 90%. This suggests that CLIP may be more", "confidence": 0.9993863701820374, "text_region": [[1221.0, 1749.0], [2175.0, 1749.0], [2175.0, 1805.0], [1221.0, 1805.0]]}, {"text": "effective at zero-shot transfer for tasks where its underly-", "confidence": 0.9924649596214294, "text_region": [[1224.0, 1802.0], [2175.0, 1802.0], [2175.0, 1845.0], [1224.0, 1845.0]]}, {"text": "ing representations are also high quality. The slope of a", "confidence": 0.9853895306587219, "text_region": [[1221.0, 1845.0], [2169.0, 1845.0], [2169.0, 1891.0], [1221.0, 1891.0]]}, {"text": "linear regression model predicting zero-shot performance", "confidence": 0.9986201524734497, "text_region": [[1218.0, 1887.0], [2172.0, 1894.0], [2172.0, 1950.0], [1217.0, 1944.0]]}, {"text": " as a function of fully supervised performance estimates that", "confidence": 0.984799325466156, "text_region": [[1221.0, 1940.0], [2172.0, 1944.0], [2172.0, 1990.0], [1221.0, 1987.0]]}, {"text": "for every 1% improvement in fully supervised performance,", "confidence": 0.9997133016586304, "text_region": [[1224.0, 1990.0], [2172.0, 1990.0], [2172.0, 2036.0], [1224.0, 2036.0]]}, {"text": " zero-shot performance improves by 1.28%. However, the", "confidence": 0.9933138489723206, "text_region": [[1217.0, 2033.0], [2172.0, 2029.0], [2172.0, 2086.0], [1217.0, 2089.0]]}, {"text": "95th-percentile confidence intervals still include values of", "confidence": 0.9916759133338928, "text_region": [[1224.0, 2086.0], [2175.0, 2086.0], [2175.0, 2132.0], [1224.0, 2132.0]]}, {"text": "less than 1 (0.93-1.79).", "confidence": 0.9980517029762268, "text_region": [[1224.0, 2135.0], [1600.0, 2135.0], [1600.0, 2178.0], [1224.0, 2178.0]]}], "img_idx": 0, "score": 0.9930311441421509}
{"type": "text", "bbox": [218, 1123, 1158, 1507], "res": [{"text": "Figure 7. The data efficiency of zero-shot transfer varies", "confidence": 0.9806747436523438, "text_region": [[220.0, 1119.0], [1164.0, 1119.0], [1164.0, 1162.0], [220.0, 1162.0]]}, {"text": "widely. Calculating the number of labeled examples per class", "confidence": 0.9902228116989136, "text_region": [[216.0, 1158.0], [1161.0, 1158.0], [1161.0, 1204.0], [216.0, 1204.0]]}, {"text": "a linear classifier on the same CLIP feature space requires to match", "confidence": 0.997133731842041, "text_region": [[216.0, 1204.0], [1164.0, 1204.0], [1164.0, 1251.0], [216.0, 1251.0]]}, {"text": "the performance of the zero-shot classifier contextualizes the ef-", "confidence": 0.998480498790741, "text_region": [[216.0, 1251.0], [1167.0, 1251.0], [1167.0, 1297.0], [216.0, 1297.0]]}, {"text": "fectiveness of zero-shot transfer. Values are estimated based on", "confidence": 0.9954087734222412, "text_region": [[213.0, 1290.0], [1164.0, 1294.0], [1164.0, 1340.0], [213.0, 1336.0]]}, {"text": "log-linear interpolation of 1, 2, 4, 8, 16-shot and fully supervised", "confidence": 0.9949167966842651, "text_region": [[220.0, 1336.0], [1161.0, 1336.0], [1161.0, 1383.0], [220.0, 1383.0]]}, {"text": "results. Performance varies widely from still underperforming a", "confidence": 0.9896612763404846, "text_region": [[216.0, 1379.0], [1164.0, 1379.0], [1164.0, 1426.0], [216.0, 1426.0]]}, {"text": " one-shot classifier on two datasets to matching an estimated 184", "confidence": 0.9827703237533569, "text_region": [[216.0, 1426.0], [1164.0, 1426.0], [1164.0, 1472.0], [216.0, 1472.0]]}, {"text": "labeled examples per class.", "confidence": 0.9925413727760315, "text_region": [[220.0, 1468.0], [612.0, 1468.0], [612.0, 1515.0], [220.0, 1515.0]]}], "img_idx": 0, "score": 0.992149293422699}
{"type": "text", "bbox": [217, 1588, 1157, 2052], "res": [{"text": "have widely varying efficiency per dataset from less than 1", "confidence": 0.9940459132194519, "text_region": [[220.0, 1584.0], [1164.0, 1584.0], [1164.0, 1630.0], [220.0, 1630.0]]}, {"text": "labeled example per class to 184. Two datasets, Flowers102", "confidence": 0.9966930150985718, "text_region": [[216.0, 1627.0], [1164.0, 1627.0], [1164.0, 1683.0], [216.0, 1683.0]]}, {"text": "and EuroSAT underperform one-shot models. Half of the", "confidence": 0.9796084761619568, "text_region": [[220.0, 1680.0], [1161.0, 1680.0], [1161.0, 1726.0], [220.0, 1726.0]]}, {"text": "datasets require less than 5 examples per class with a median", "confidence": 0.9909371137619019, "text_region": [[220.0, 1726.0], [1161.0, 1726.0], [1161.0, 1772.0], [220.0, 1772.0]]}, {"text": "of 5.4. However, the mean estimated data efficiency is 20.8", "confidence": 0.9838436841964722, "text_region": [[216.0, 1775.0], [1164.0, 1775.0], [1164.0, 1822.0], [216.0, 1822.0]]}, {"text": " examples per class. This is due to the 20% of datasets", "confidence": 0.9880220293998718, "text_region": [[209.0, 1818.0], [1167.0, 1815.0], [1168.0, 1871.0], [210.0, 1874.0]]}, {"text": "where supervised classifiers require many labeled examples", "confidence": 0.9918334484100342, "text_region": [[220.0, 1871.0], [1161.0, 1871.0], [1161.0, 1917.0], [220.0, 1917.0]]}, {"text": "per class in order to match performance. On ImageNet,", "confidence": 0.9995825290679932, "text_region": [[216.0, 1921.0], [1164.0, 1921.0], [1164.0, 1967.0], [216.0, 1967.0]]}, {"text": "zero-shot CLIP matches the performance of a 16-shot linear", "confidence": 0.9952676892280579, "text_region": [[216.0, 1967.0], [1164.0, 1967.0], [1164.0, 2013.0], [216.0, 2013.0]]}, {"text": " classifier trained on the same feature space.", "confidence": 0.9948471784591675, "text_region": [[210.0, 2006.0], [921.0, 2010.0], [921.0, 2066.0], [209.0, 2062.0]]}], "img_idx": 0, "score": 0.9887463450431824}
{"type": "text", "bbox": [1227, 1138, 2167, 1389], "res": [{"text": "Figure 8. Zero-shot performance is correlated with linear", "confidence": 0.9820460081100464, "text_region": [[1224.0, 1132.0], [2172.0, 1132.0], [2172.0, 1178.0], [1224.0, 1178.0]]}, {"text": " probe performance but still mostly sub-optimal. Comparing", "confidence": 0.9684244394302368, "text_region": [[1221.0, 1172.0], [2175.0, 1172.0], [2175.0, 1228.0], [1221.0, 1228.0]]}, {"text": "zero-shot and linear probe performance across datasets shows a", "confidence": 0.9826470613479614, "text_region": [[1224.0, 1221.0], [2172.0, 1221.0], [2172.0, 1267.0], [1224.0, 1267.0]]}, {"text": "strong correlation with zero-shot performance mostly shifted 10 to", "confidence": 0.9859155416488647, "text_region": [[1224.0, 1264.0], [2172.0, 1264.0], [2172.0, 1310.0], [1224.0, 1310.0]]}, {"text": " 25 points lower. On only 5 datasets does zero-shot performance", "confidence": 0.9916244149208069, "text_region": [[1221.0, 1303.0], [2172.0, 1310.0], [2172.0, 1356.0], [1221.0, 1350.0]]}, {"text": "approach linear probe performance (\u22643 point difference).", "confidence": 0.978320300579071, "text_region": [[1227.0, 1353.0], [2059.0, 1353.0], [2059.0, 1399.0], [1227.0, 1399.0]]}], "img_idx": 0, "score": 0.9840567111968994}
{"type": "figure", "bbox": [1193, 263, 2172, 1082], "res": [{"text": "100", "confidence": 0.9988527297973633, "text_region": [[1261.0, 261.0], [1324.0, 261.0], [1324.0, 297.0], [1261.0, 297.0]]}, {"text": "STL10", "confidence": 0.9579823613166809, "text_region": [[2022.0, 274.0], [2072.0, 274.0], [2072.0, 300.0], [2022.0, 300.0]]}, {"text": "90", "confidence": 0.9995958805084229, "text_region": [[1281.0, 356.0], [1324.0, 356.0], [1324.0, 386.0], [1281.0, 386.0]]}, {"text": "80", "confidence": 0.9917178153991699, "text_region": [[1274.0, 439.0], [1320.0, 439.0], [1320.0, 479.0], [1274.0, 479.0]]}, {"text": "70", "confidence": 0.9997453689575195, "text_region": [[1284.0, 535.0], [1324.0, 535.0], [1324.0, 564.0], [1284.0, 564.0]]}, {"text": "KiHatesf/Memes", "confidence": 0.8225483298301697, "text_region": [[1733.0, 601.0], [1856.0, 601.0], [1856.0, 637.0], [1733.0, 637.0]]}, {"text": "dl", "confidence": 0.6370323896408081, "text_region": [[1234.0, 630.0], [1254.0, 630.0], [1254.0, 660.0], [1234.0, 660.0]]}, {"text": "60", "confidence": 0.9991918802261353, "text_region": [[1284.0, 627.0], [1317.0, 627.0], [1317.0, 657.0], [1284.0, 657.0]]}, {"text": "FER2013", "confidence": 0.9996300935745239, "text_region": [[1746.0, 647.0], [1829.0, 647.0], [1829.0, 676.0], [1746.0, 676.0]]}, {"text": "50", "confidence": 0.9997776746749878, "text_region": [[1281.0, 713.0], [1317.0, 713.0], [1317.0, 746.0], [1281.0, 746.0]]}, {"text": "S", "confidence": 0.6055039167404175, "text_region": [[1234.0, 736.0], [1251.0, 736.0], [1251.0, 756.0], [1234.0, 756.0]]}, {"text": "40", "confidence": 0.9996887445449829, "text_region": [[1277.0, 802.0], [1327.0, 802.0], [1327.0, 835.0], [1277.0, 835.0]]}, {"text": "FGVCAircraft", "confidence": 0.9981957077980042, "text_region": [[1810.0, 828.0], [1920.0, 832.0], [1919.0, 858.0], [1809.0, 854.0]]}, {"text": "KITTI Distance", "confidence": 0.9948176741600037, "text_region": [[1786.0, 865.0], [1916.0, 865.0], [1916.0, 898.0], [1786.0, 898.0]]}, {"text": "30", "confidence": 0.9995105266571045, "text_region": [[1277.0, 888.0], [1327.0, 888.0], [1327.0, 931.0], [1277.0, 931.0]]}, {"text": "CLEVRCounts", "confidence": 0.9996843338012695, "text_region": [[1706.0, 940.0], [1829.0, 940.0], [1829.0, 977.0], [1706.0, 977.0]]}, {"text": "r = 0.82", "confidence": 0.9888594150543213, "text_region": [[1946.0, 950.0], [2059.0, 950.0], [2059.0, 987.0], [1946.0, 987.0]]}, {"text": "20", "confidence": 0.9996114373207092, "text_region": [[1281.0, 987.0], [1320.0, 987.0], [1320.0, 1013.0], [1281.0, 1013.0]]}, {"text": "20", "confidence": 0.9981076717376709, "text_region": [[1307.0, 1010.0], [1364.0, 1010.0], [1364.0, 1046.0], [1307.0, 1046.0]]}, {"text": "30", "confidence": 0.9997037649154663, "text_region": [[1407.0, 1007.0], [1454.0, 1007.0], [1454.0, 1046.0], [1407.0, 1046.0]]}, {"text": "40", "confidence": 0.9997044801712036, "text_region": [[1497.0, 1010.0], [1550.0, 1010.0], [1550.0, 1049.0], [1497.0, 1049.0]]}, {"text": "50", "confidence": 0.999786376953125, "text_region": [[1593.0, 1013.0], [1636.0, 1013.0], [1636.0, 1043.0], [1593.0, 1043.0]]}, {"text": "60", "confidence": 0.999405026435852, "text_region": [[1683.0, 1007.0], [1730.0, 1007.0], [1730.0, 1046.0], [1683.0, 1046.0]]}, {"text": "70", "confidence": 0.9995380640029907, "text_region": [[1776.0, 1007.0], [1826.0, 1007.0], [1826.0, 1046.0], [1776.0, 1046.0]]}, {"text": "80", "confidence": 0.9682570695877075, "text_region": [[1866.0, 1007.0], [1916.0, 1007.0], [1916.0, 1046.0], [1866.0, 1046.0]]}, {"text": "90", "confidence": 0.9962154626846313, "text_region": [[1953.0, 1008.0], [2007.0, 998.0], [2015.0, 1041.0], [1961.0, 1052.0]]}, {"text": "100", "confidence": 0.996546745300293, "text_region": [[2039.0, 1010.0], [2105.0, 1010.0], [2105.0, 1049.0], [2039.0, 1049.0]]}, {"text": "Linear Probe CLIP Performance", "confidence": 0.9953977465629578, "text_region": [[1497.0, 1046.0], [1919.0, 1046.0], [1919.0, 1089.0], [1497.0, 1089.0]]}], "img_idx": 0, "score": 0.9561460018157959}
{"type": "figure", "bbox": [200, 257, 1161, 1022], "res": [{"text": "FER2013", "confidence": 0.9986240267753601, "text_region": [[293.0, 264.0], [426.0, 264.0], [426.0, 297.0], [293.0, 297.0]]}, {"text": "184", "confidence": 0.9990755915641785, "text_region": [[1084.0, 271.0], [1124.0, 271.0], [1124.0, 294.0], [1084.0, 294.0]]}, {"text": "CIFAR10", "confidence": 0.9910436868667603, "text_region": [[299.0, 297.0], [402.0, 297.0], [402.0, 320.0], [299.0, 320.0]]}, {"text": "Foodl01", "confidence": 0.907554566860199, "text_region": [[296.0, 323.0], [406.0, 323.0], [406.0, 346.0], [296.0, 346.0]]}, {"text": "OxfordPets", "confidence": 0.9943154454231262, "text_region": [[263.0, 350.0], [402.0, 350.0], [402.0, 373.0], [263.0, 373.0]]}, {"text": "Country211", "confidence": 0.996708869934082, "text_region": [[256.0, 373.0], [409.0, 373.0], [409.0, 406.0], [256.0, 406.0]]}, {"text": "PCam", "confidence": 0.9697046875953674, "text_region": [[336.0, 429.0], [399.0, 429.0], [399.0, 452.0], [336.0, 452.0]]}, {"text": "SST2", "confidence": 0.9453411102294922, "text_region": [[343.0, 455.0], [399.0, 455.0], [399.0, 479.0], [343.0, 479.0]]}, {"text": "4.4", "confidence": 0.9999598860740662, "text_region": [[489.0, 455.0], [529.0, 455.0], [529.0, 479.0], [489.0, 479.0]]}, {"text": "Kinetics700", "confidence": 0.9988731145858765, "text_region": [[256.0, 479.0], [402.0, 479.0], [402.0, 515.0], [256.0, 515.0]]}, {"text": "STL10", "confidence": 0.9398224949836731, "text_region": [[329.0, 508.0], [399.0, 508.0], [399.0, 531.0], [329.0, 531.0]]}, {"text": "CIFAR100", "confidence": 0.9989264011383057, "text_region": [[279.0, 531.0], [406.0, 531.0], [406.0, 564.0], [279.0, 564.0]]}, {"text": "2.0", "confidence": 0.9996843338012695, "text_region": [[486.0, 535.0], [522.0, 535.0], [522.0, 558.0], [486.0, 558.0]]}, {"text": "StanfordCa", "confidence": 0.9786844253540039, "text_region": [[229.0, 588.0], [377.0, 577.0], [380.0, 613.0], [231.0, 625.0]]}, {"text": "MNIST", "confidence": 0.9957531690597534, "text_region": [[329.0, 614.0], [402.0, 614.0], [402.0, 640.0], [329.0, 640.0]]}, {"text": "SUN397", "confidence": 0.9985764622688293, "text_region": [[299.0, 637.0], [402.0, 637.0], [402.0, 670.0], [299.0, 670.0]]}, {"text": "3.9", "confidence": 0.9984540939331055, "text_region": [[442.0, 640.0], [479.0, 640.0], [479.0, 667.0], [442.0, 667.0]]}, {"text": "Caltech101", "confidence": 0.9728938341140747, "text_region": [[256.0, 663.0], [406.0, 663.0], [406.0, 696.0], [256.0, 696.0]]}, {"text": "KITTI Distan", "confidence": 0.9943452477455139, "text_region": [[223.0, 690.0], [373.0, 690.0], [373.0, 726.0], [223.0, 726.0]]}, {"text": "UCF101", "confidence": 0.9982221722602844, "text_region": [[303.0, 716.0], [406.0, 716.0], [406.0, 749.0], [303.0, 749.0]]}, {"text": "C", "confidence": 0.7928563952445984, "text_region": [[449.0, 723.0], [469.0, 723.0], [469.0, 739.0], [449.0, 739.0]]}, {"text": "Birdsna", "confidence": 0.9971429705619812, "text_region": [[293.0, 742.0], [392.0, 742.0], [392.0, 779.0], [293.0, 779.0]]}, {"text": "DTD", "confidence": 0.9948434233665466, "text_region": [[346.0, 769.0], [409.0, 769.0], [409.0, 805.0], [346.0, 805.0]]}, {"text": "FGVCAi", "confidence": 0.9970661997795105, "text_region": [[239.0, 795.0], [339.0, 795.0], [339.0, 832.0], [239.0, 832.0]]}, {"text": ".0", "confidence": 0.9930441379547119, "text_region": [[449.0, 802.0], [472.0, 802.0], [472.0, 825.0], [449.0, 825.0]]}, {"text": "GTSRB", "confidence": 0.9953368306159973, "text_region": [[313.0, 822.0], [406.0, 822.0], [406.0, 858.0], [313.0, 858.0]]}, {"text": ".5", "confidence": 0.9980746507644653, "text_region": [[446.0, 855.0], [469.0, 855.0], [469.0, 878.0], [446.0, 878.0]]}, {"text": "RESISC45", "confidence": 0.9968148469924927, "text_region": [[279.0, 874.0], [406.0, 874.0], [406.0, 911.0], [279.0, 911.0]]}, {"text": "1.5", "confidence": 0.9983272552490234, "text_region": [[436.0, 878.0], [466.0, 878.0], [466.0, 904.0], [436.0, 904.0]]}, {"text": "Mean:n.20.8", "confidence": 0.9394795894622803, "text_region": [[937.0, 882.0], [1120.0, 874.0], [1122.0, 920.0], [939.0, 928.0]]}, {"text": "EuroSAT", "confidence": 0.9865134358406067, "text_region": [[292.0, 905.0], [411.0, 897.0], [413.0, 930.0], [294.0, 938.0]]}, {"text": "Flowers102 0.9", "confidence": 0.9972802996635437, "text_region": [[256.0, 931.0], [472.0, 931.0], [472.0, 967.0], [256.0, 967.0]]}, {"text": "50", "confidence": 0.9997832179069519, "text_region": [[582.0, 964.0], [629.0, 964.0], [629.0, 1003.0], [582.0, 1003.0]]}, {"text": "75100125150", "confidence": 0.9613128304481506, "text_region": [[612.0, 960.0], [991.0, 960.0], [991.0, 1007.0], [612.0, 1007.0]]}, {"text": "25", "confidence": 0.9951629042625427, "text_region": [[499.0, 970.0], [529.0, 970.0], [529.0, 1000.0], [499.0, 1000.0]]}, {"text": "175", "confidence": 0.9992422461509705, "text_region": [[975.0, 967.0], [1081.0, 967.0], [1081.0, 1003.0], [975.0, 1003.0]]}, {"text": "\u3000200", "confidence": 0.8508493304252625, "text_region": [[1081.0, 973.0], [1164.0, 973.0], [1164.0, 1003.0], [1081.0, 1003.0]]}, {"text": "# of labeled examples per class", "confidence": 0.9923420548439026, "text_region": [[572.0, 1003.0], [988.0, 1003.0], [988.0, 1046.0], [572.0, 1046.0]]}], "img_idx": 0, "score": 0.9383611083030701}
{"type": "figure_caption", "bbox": [583, 1015, 977, 1064], "res": [{"text": "# of labeled examples per class", "confidence": 0.9923420548439026, "text_region": [[572.0, 1003.0], [988.0, 1003.0], [988.0, 1046.0], [572.0, 1046.0]]}, {"text": "required to match zero-shot", "confidence": 0.996428906917572, "text_region": [[592.0, 1036.0], [964.0, 1033.0], [965.0, 1069.0], [592.0, 1073.0]]}], "img_idx": 0, "score": 0.7362527251243591}
{"type": "header", "bbox": [2129, 193, 2166, 219], "res": [{"text": "10", "confidence": 0.9997665882110596, "text_region": [[2129.0, 191.0], [2169.0, 191.0], [2169.0, 221.0], [2129.0, 221.0]]}], "img_idx": 0, "score": 0.9072451591491699}
{"type": "header", "bbox": [485, 193, 1367, 224], "res": [{"text": "Learning Transferable Visual Models From Natural Language Supervision", "confidence": 0.9968586564064026, "text_region": [[220.0, 188.0], [1374.0, 188.0], [1374.0, 231.0], [220.0, 231.0]]}], "img_idx": 0, "score": 0.6499520540237427}
