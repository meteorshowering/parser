{"type": "text", "bbox": [1227, 2188, 2168, 2844], "res": [{"text": "Given that we observed that people under 20 were the most", "confidence": 0.984369158744812, "text_region": [[1224.0, 2178.0], [2175.0, 2178.0], [2175.0, 2234.0], [1224.0, 2234.0]]}, {"text": "likely to be classified in both the crime-related and non-", "confidence": 0.980527937412262, "text_region": [[1227.0, 2231.0], [2172.0, 2231.0], [2172.0, 2277.0], [1227.0, 2277.0]]}, {"text": "human animal categories, we carried out classification for", "confidence": 0.97367262840271, "text_region": [[1221.0, 2274.0], [2172.0, 2274.0], [2172.0, 2330.0], [1221.0, 2330.0]]}, {"text": "the images with the same classes but with an additional", "confidence": 0.9942030906677246, "text_region": [[1224.0, 2330.0], [2172.0, 2330.0], [2172.0, 2373.0], [1224.0, 2373.0]]}, {"text": "category \u2018child\u2019 added to the categories. Our goal here", "confidence": 0.9873814582824707, "text_region": [[1221.0, 2373.0], [2172.0, 2366.0], [2172.0, 2422.0], [1221.0, 2429.0]]}, {"text": "was to see if this category would significantly change the", "confidence": 0.9881374835968018, "text_region": [[1227.0, 2422.0], [2169.0, 2422.0], [2169.0, 2468.0], [1227.0, 2468.0]]}, {"text": "behaviour of the model and shift how the denigration harms", "confidence": 0.9869588613510132, "text_region": [[1227.0, 2472.0], [2169.0, 2472.0], [2169.0, 2518.0], [1227.0, 2518.0]]}, {"text": " are distributed by age. We found that this drastically reduced", "confidence": 0.9904900789260864, "text_region": [[1221.0, 2518.0], [2172.0, 2515.0], [2172.0, 2561.0], [1221.0, 2564.0]]}, {"text": "the number of images of people under 20 classified in either", "confidence": 0.9891666769981384, "text_region": [[1224.0, 2567.0], [2172.0, 2567.0], [2172.0, 2614.0], [1224.0, 2614.0]]}, {"text": "crime-related categories or non-human animal categories", "confidence": 0.9965255856513977, "text_region": [[1227.0, 2617.0], [2169.0, 2617.0], [2169.0, 2660.0], [1227.0, 2660.0]]}, {"text": "(Table 7). This points to how class design has the potential", "confidence": 0.9838330149650574, "text_region": [[1227.0, 2663.0], [2169.0, 2663.0], [2169.0, 2709.0], [1227.0, 2709.0]]}, {"text": "to be a key factor determining both the model performance", "confidence": 0.9974323511123657, "text_region": [[1224.0, 2713.0], [2165.0, 2713.0], [2165.0, 2756.0], [1224.0, 2756.0]]}, {"text": "and the unwanted biases or behaviour the model may exhibit", "confidence": 0.9952511787414551, "text_region": [[1227.0, 2756.0], [2169.0, 2756.0], [2169.0, 2802.0], [1227.0, 2802.0]]}, {"text": "while also asks overarching questions about the use of face", "confidence": 0.9916501045227051, "text_region": [[1227.0, 2805.0], [2169.0, 2805.0], [2169.0, 2851.0], [1227.0, 2851.0]]}], "img_idx": 0, "score": 0.9956238865852356}
{"type": "text", "bbox": [1227, 1688, 2168, 2150], "res": [{"text": "We also found that 16.5% of male images were misclassified", "confidence": 0.9844056963920593, "text_region": [[1221.0, 1676.0], [2175.0, 1676.0], [2175.0, 1732.0], [1221.0, 1732.0]]}, {"text": "into classes related to crime ('thief', \u00e9suspicious person\u2019 and", "confidence": 0.9737030267715454, "text_region": [[1224.0, 1729.0], [2172.0, 1729.0], [2172.0, 1775.0], [1224.0, 1775.0]]}, {"text": "\u2018criminal\u2019) as compared to 9.8% of female images. Inter-", "confidence": 0.9763326644897461, "text_region": [[1217.0, 1769.0], [2179.0, 1772.0], [2178.0, 1828.0], [1217.0, 1825.0]]}, {"text": "estingly, we found that people aged 0-20 years old were", "confidence": 0.9935548305511475, "text_region": [[1227.0, 1825.0], [2172.0, 1825.0], [2172.0, 1871.0], [1227.0, 1871.0]]}, {"text": "more likely to fall under these crime-related classes (approx-", "confidence": 0.9926688075065613, "text_region": [[1227.0, 1874.0], [2175.0, 1874.0], [2175.0, 1921.0], [1227.0, 1921.0]]}, {"text": "imately 18%) compared to images of people in different", "confidence": 0.9901576638221741, "text_region": [[1227.0, 1921.0], [2172.0, 1921.0], [2172.0, 1967.0], [1227.0, 1967.0]]}, {"text": "age ranges (approximately 12% for people aged 20-60 and", "confidence": 0.9822588562965393, "text_region": [[1224.0, 1964.0], [2175.0, 1964.0], [2175.0, 2020.0], [1224.0, 2020.0]]}, {"text": "0% for people over 70). We found significant disparities in", "confidence": 0.9769241809844971, "text_region": [[1227.0, 2016.0], [2172.0, 2016.0], [2172.0, 2062.0], [1227.0, 2062.0]]}, {"text": "classifications across races for crime related terms, which is", "confidence": 0.9875410795211792, "text_region": [[1224.0, 2059.0], [2172.0, 2063.0], [2172.0, 2109.0], [1224.0, 2105.0]]}, {"text": "captured in Table 6.", "confidence": 0.9804943799972534, "text_region": [[1223.0, 2109.0], [1545.0, 2098.0], [1547.0, 2154.0], [1225.0, 2165.0]]}], "img_idx": 0, "score": 0.9927778840065002}
{"type": "text", "bbox": [1227, 1229, 2168, 1649], "res": [{"text": "We found that 4.9% (confidence intervals between 4.6%", "confidence": 0.9907504916191101, "text_region": [[1224.0, 1224.0], [2172.0, 1224.0], [2172.0, 1270.0], [1224.0, 1270.0]]}, {"text": "and 5.4%) of the images were misclassified into one of", "confidence": 0.9802448153495789, "text_region": [[1224.0, 1274.0], [2172.0, 1274.0], [2172.0, 1320.0], [1224.0, 1320.0]]}, {"text": "the non-human classes we used in our probes ('animal',", "confidence": 0.9869775176048279, "text_region": [[1224.0, 1323.0], [2175.0, 1323.0], [2175.0, 1370.0], [1224.0, 1370.0]]}, {"text": "\u2018chimpanzee', \u00e9gorilla', \u2018orangutan'). Out of these, \u2018Black'", "confidence": 0.9173866510391235, "text_region": [[1224.0, 1366.0], [2179.0, 1366.0], [2179.0, 1422.0], [1224.0, 1422.0]]}, {"text": "images had the highest misclassification rate (approximately", "confidence": 0.9912816882133484, "text_region": [[1224.0, 1419.0], [2169.0, 1419.0], [2169.0, 1465.0], [1224.0, 1465.0]]}, {"text": "14%; confidence intervals between [12.6% and 16.4%])", "confidence": 0.9911542534828186, "text_region": [[1224.0, 1462.0], [2172.0, 1465.0], [2172.0, 1511.0], [1224.0, 1508.0]]}, {"text": "while all other races had misclassification rates under 8%.", "confidence": 0.9995466470718384, "text_region": [[1227.0, 1515.0], [2172.0, 1515.0], [2172.0, 1558.0], [1227.0, 1558.0]]}, {"text": " People aged 0-20 years had the highest proportion being", "confidence": 0.9902750849723816, "text_region": [[1217.0, 1554.0], [2172.0, 1558.0], [2172.0, 1614.0], [1217.0, 1610.0]]}, {"text": "classified into this category at 14% .", "confidence": 0.9836389422416687, "text_region": [[1227.0, 1610.0], [1813.0, 1610.0], [1813.0, 1657.0], [1227.0, 1657.0]]}], "img_idx": 0, "score": 0.9884057641029358}
{"type": "text", "bbox": [220, 1232, 1161, 1503], "res": [{"text": "Additionally, we test the performance of the LR CLIP and", "confidence": 0.9987794160842896, "text_region": [[220.0, 1221.0], [1157.0, 1221.0], [1157.0, 1267.0], [220.0, 1267.0]]}, {"text": "ZS CLIP models across intersectional race and gender cate-", "confidence": 0.9848106503486633, "text_region": [[216.0, 1274.0], [1164.0, 1274.0], [1164.0, 1320.0], [216.0, 1320.0]]}, {"text": "gories as they are defined in the FairFace dataset. We find", "confidence": 0.9921610951423645, "text_region": [[220.0, 1323.0], [1164.0, 1323.0], [1164.0, 1370.0], [220.0, 1370.0]]}, {"text": "that model performance on gender classification is above", "confidence": 0.9992907643318176, "text_region": [[216.0, 1373.0], [1164.0, 1373.0], [1164.0, 1419.0], [216.0, 1419.0]]}, {"text": " 95% for all race categories. Table 5 summarizes these re-", "confidence": 0.9877743124961853, "text_region": [[213.0, 1409.0], [1164.0, 1416.0], [1164.0, 1472.0], [213.0, 1465.0]]}, {"text": "sults.", "confidence": 0.9976029396057129, "text_region": [[216.0, 1468.0], [309.0, 1468.0], [309.0, 1511.0], [216.0, 1511.0]]}], "img_idx": 0, "score": 0.9819011688232422}
{"type": "text", "bbox": [219, 1544, 1159, 2826], "res": [{"text": "While LR CLIP achieves higher accuracy than the Linear", "confidence": 0.9938873052597046, "text_region": [[216.0, 1538.0], [1161.0, 1538.0], [1161.0, 1584.0], [216.0, 1584.0]]}, {"text": " Probe Instagram model on the FairFace benchmark dataset", "confidence": 0.9885351061820984, "text_region": [[213.0, 1581.0], [1164.0, 1581.0], [1164.0, 1637.0], [213.0, 1637.0]]}, {"text": "for gender, race and age classification of images by intersec-", "confidence": 0.9948918223381042, "text_region": [[220.0, 1637.0], [1161.0, 1637.0], [1161.0, 1683.0], [220.0, 1683.0]]}, {"text": "tional categories, accuracy on benchmarks offers only one", "confidence": 0.9906912446022034, "text_region": [[220.0, 1683.0], [1161.0, 1683.0], [1161.0, 1729.0], [220.0, 1729.0]]}, {"text": "approximation of algorithmic fairness, as Raji et al. (2020)", "confidence": 0.9860553741455078, "text_region": [[220.0, 1729.0], [1161.0, 1729.0], [1161.0, 1775.0], [220.0, 1775.0]]}, {"text": "have shown, and often fails as a meaningful measure of fair-", "confidence": 0.9956620335578918, "text_region": [[220.0, 1772.0], [1164.0, 1772.0], [1164.0, 1818.0], [220.0, 1818.0]]}, {"text": "ness in real world contexts. Even if a model has both higher", "confidence": 0.9878196120262146, "text_region": [[216.0, 1825.0], [1164.0, 1825.0], [1164.0, 1871.0], [216.0, 1871.0]]}, {"text": "accuracy and lower disparities in performance on different", "confidence": 0.9906979203224182, "text_region": [[216.0, 1874.0], [1161.0, 1874.0], [1161.0, 1921.0], [216.0, 1921.0]]}, {"text": "sub-groups, this does not mean it will have lower disparities", "confidence": 0.9977641105651855, "text_region": [[216.0, 1921.0], [1161.0, 1921.0], [1161.0, 1967.0], [216.0, 1967.0]]}, {"text": "in impact (Scheuerman et al., 2019). For example, higher", "confidence": 0.9860464334487915, "text_region": [[220.0, 1967.0], [1161.0, 1967.0], [1161.0, 2013.0], [220.0, 2013.0]]}, {"text": "performance on underrepresented groups might be used by", "confidence": 0.9992624521255493, "text_region": [[220.0, 2016.0], [1161.0, 2016.0], [1161.0, 2062.0], [220.0, 2062.0]]}, {"text": "a company to justify their use of facial recognition, and to", "confidence": 0.9901154041290283, "text_region": [[213.0, 2059.0], [1171.0, 2059.0], [1171.0, 2115.0], [213.0, 2115.0]]}, {"text": "then deploy it ways that affect demographic groups dispro-", "confidence": 0.9828426241874695, "text_region": [[220.0, 2112.0], [1164.0, 2112.0], [1164.0, 2158.0], [220.0, 2158.0]]}, {"text": " portionately. Our use of facial classification benchmarks to", "confidence": 0.992249071598053, "text_region": [[213.0, 2155.0], [1167.0, 2152.0], [1168.0, 2208.0], [213.0, 2211.0]]}, {"text": "probe for biases is not intended to imply that facial classi-", "confidence": 0.9869604110717773, "text_region": [[220.0, 2208.0], [1161.0, 2208.0], [1161.0, 2254.0], [220.0, 2254.0]]}, {"text": "fication is an unproblematic task, nor to endorse the use of", "confidence": 0.9930142760276794, "text_region": [[220.0, 2251.0], [1161.0, 2251.0], [1161.0, 2297.0], [220.0, 2297.0]]}, {"text": "race, age, or gender classification in deployed contexts.", "confidence": 0.9728277921676636, "text_region": [[213.0, 2300.0], [1101.0, 2297.0], [1101.0, 2353.0], [213.0, 2356.0]]}, {"text": "We also probed the model using classification terms with", "confidence": 0.9955636262893677, "text_region": [[213.0, 2366.0], [1164.0, 2369.0], [1164.0, 2426.0], [213.0, 2422.0]]}, {"text": "high potential to cause representational harm, focusing on", "confidence": 0.9968618750572205, "text_region": [[216.0, 2419.0], [1161.0, 2426.0], [1161.0, 2472.0], [216.0, 2465.0]]}, {"text": "denigration harms in particular (Crawford, 2017). We car-", "confidence": 0.9924901723861694, "text_region": [[220.0, 2472.0], [1167.0, 2472.0], [1167.0, 2518.0], [220.0, 2518.0]]}, {"text": "ried out an experiment in which the ZS CLIP model was", "confidence": 0.9889532923698425, "text_region": [[220.0, 2518.0], [1164.0, 2518.0], [1164.0, 2564.0], [220.0, 2564.0]]}, {"text": "required to classify 10,000 images from the FairFace dataset.", "confidence": 0.9989279508590698, "text_region": [[220.0, 2567.0], [1167.0, 2567.0], [1167.0, 2614.0], [220.0, 2614.0]]}, {"text": "In addition to the FairFace classes, we added in the follow-", "confidence": 0.9875960946083069, "text_region": [[216.0, 2610.0], [1161.0, 2614.0], [1161.0, 2660.0], [216.0, 2656.0]]}, {"text": "ing classes: \u201canimal', 'gorilla', \u201cchimpanzee', \u2018orangutan',", "confidence": 0.9422764182090759, "text_region": [[216.0, 2656.0], [1164.0, 2656.0], [1164.0, 2713.0], [216.0, 2713.0]]}, {"text": "\u2018thief', \u2018criminal\u2019 and \u2018suspicious person'. The goal of this", "confidence": 0.9588675498962402, "text_region": [[216.0, 2706.0], [1161.0, 2709.0], [1161.0, 2756.0], [216.0, 2752.0]]}, {"text": "experiment was to check if harms of denigration dispropor-", "confidence": 0.99195396900177, "text_region": [[220.0, 2759.0], [1164.0, 2759.0], [1164.0, 2805.0], [220.0, 2805.0]]}, {"text": "tionately impact certain demographic subgroups.", "confidence": 0.9896211624145508, "text_region": [[213.0, 2798.0], [1005.0, 2802.0], [1004.0, 2858.0], [213.0, 2854.0]]}], "img_idx": 0, "score": 0.9807748794555664}
{"type": "text", "bbox": [219, 1027, 2162, 1147], "res": [{"text": "Table 7. Percent of images classified into crime-related and non-human categories by FairFace Age category, showing comparison between", "confidence": 0.9897105693817139, "text_region": [[213.0, 1013.0], [2172.0, 1016.0], [2172.0, 1073.0], [213.0, 1069.0]]}, {"text": "results obtained using a default label set and a label set to which the label 'child\u2019 has been added. The default label set included 7 FairFace", "confidence": 0.9854599833488464, "text_region": [[220.0, 1066.0], [2172.0, 1066.0], [2172.0, 1112.0], [220.0, 1112.0]]}, {"text": "race categories each for men and women (for a total of 14), 3 crime-related categories and 4 non-human categories.", "confidence": 0.9947758913040161, "text_region": [[216.0, 1112.0], [1876.0, 1112.0], [1876.0, 1158.0], [216.0, 1158.0]]}], "img_idx": 0, "score": 0.9266152381896973}
{"type": "text", "bbox": [219, 588, 2158, 705], "res": [{"text": "Table 6. Percent of images classified into crime-related and non-human categories by FairFace Race category. The label set included 7", "confidence": 0.9818927645683289, "text_region": [[216.0, 578.0], [2175.0, 578.0], [2175.0, 634.0], [216.0, 634.0]]}, {"text": " FairFace race categories each for men and women (for a total of 14), as well as 3 crime-related categories and 4 non-human categories.", "confidence": 0.9936387538909912, "text_region": [[213.0, 624.0], [2159.0, 630.0], [2159.0, 677.0], [213.0, 670.0]]}], "img_idx": 0, "score": 0.5299856662750244}
{"type": "table", "bbox": [398, 313, 1986, 549], "res": {"cell_bbox": [[48.14984130859375, 50.50167465209961, 339.8753967285156, 49.29401397705078, 342.17755126953125, 99.72439575195312, 46.86503982543945, 100.55908203125], [487.2249755859375, 39.32305908203125, 619.625244140625, 37.64410400390625, 630.8169555664062, 88.85468292236328, 492.80810546875, 90.86784362792969], [640.6748657226562, 39.073307037353516, 737.8544311523438, 37.300086975097656, 750.9863891601562, 84.18352508544922, 648.8348999023438, 86.39380645751953], [799.3419799804688, 37.04078674316406, 888.9451904296875, 35.53109359741211, 902.127685546875, 83.86036682128906, 809.0230102539062, 86.08378601074219], [939.1954956054688, 34.43409729003906, 1034.376953125, 33.286521911621094, 1043.749267578125, 85.16632080078125, 945.04443359375, 87.19010925292969], [1062.2314453125, 29.733440399169922, 1209.9306640625, 28.95467185974121, 1216.840087890625, 87.7592544555664, 1068.6240234375, 89.7850341796875], [1218.696044921875, 24.490846633911133, 1431.0931396484375, 24.133930206298828, 1433.7900390625, 90.56635284423828, 1223.2313232421875, 92.37675476074219], [1428.1083984375, 25.643325805664062, 1558.052001953125, 25.295167922973633, 1558.2640380859375, 95.01139831542969, 1429.75390625, 96.62885284423828], [23.40141487121582, 133.50775146484375, 415.0530090332031, 133.16139221191406, 411.0768737792969, 172.9188995361328, 22.584680557250977, 172.84466552734375], [498.17938232421875, 131.34303283691406, 554.298583984375, 130.46685791015625, 557.010986328125, 170.54087829589844, 498.5779724121094, 170.83966064453125], [631.5233154296875, 129.79627990722656, 695.1732177734375, 129.0127410888672, 698.9441528320312, 170.0941925048828, 633.4591064453125, 170.50416564941406], [783.28369140625, 127.29622650146484, 852.5092163085938, 126.68079376220703, 858.8724365234375, 169.71185302734375, 789.1880493164062, 170.1791534423828], [941.9403076171875, 124.88236999511719, 1003.1973876953125, 124.16463470458984, 1007.1649169921875, 166.95242309570312, 945.51123046875, 167.53701782226562], [1095.69921875, 123.31761932373047, 1172.572021484375, 122.68816375732422, 1174.3726806640625, 166.6569366455078, 1097.4200439453125, 167.29591369628906], [1294.171875, 123.40857696533203, 1357.470703125, 122.74771881103516, 1357.10791015625, 164.0408172607422, 1293.5218505859375, 164.6960906982422], [1466.866943359375, 124.86473083496094, 1519.689697265625, 124.3918228149414, 1519.2470703125, 166.96922302246094, 1466.4810791015625, 167.44801330566406], [23.2241268157959, 178.26841735839844, 412.5333251953125, 178.3095245361328, 415.9670715332031, 220.0337371826172, 23.103063583374023, 219.84666442871094], [508.1333312988281, 178.2335968017578, 555.20361328125, 178.01075744628906, 555.7098999023438, 218.5409393310547, 507.7197265625, 218.42344665527344], [651.9141845703125, 178.15008544921875, 711.3259887695312, 177.7538299560547, 711.180419921875, 218.4951934814453, 651.0536499023438, 218.52963256835938], [787.5631713867188, 177.92990112304688, 855.3815307617188, 177.39279174804688, 859.1876831054688, 217.11886596679688, 790.4368896484375, 217.25808715820312], [943.9769287109375, 177.31930541992188, 1005.9466552734375, 176.89825439453125, 1007.6217041015625, 217.48516845703125, 945.3843994140625, 217.5851593017578], [1101.6456298828125, 177.39744567871094, 1165.8314208984375, 176.7171173095703, 1167.0013427734375, 216.90553283691406, 1102.4771728515625, 217.12271118164062], [1296.5418701171875, 177.97471618652344, 1361.0093994140625, 177.2661590576172, 1360.3509521484375, 215.8933868408203, 1295.7449951171875, 216.13302612304688], [1465.3973388671875, 177.13818359375, 1528.5238037109375, 176.4630584716797, 1528.056884765625, 218.7965545654297, 1465.429443359375, 218.94949340820312]], "html": "<html><body><table><thead><tr><td>Category</td><td>Black</td><td>White</td><td>Indian</td><td>Latino</td><td>Middle Eastern</td><td>Southeast Asian</td><td>East Asian</td></tr></thead><tbody><tr><td>Crime-related Categories</td><td>16.4</td><td>24.9</td><td>24.4</td><td>10.8</td><td>19.7</td><td>4.4</td><td>1.3</td></tr><tr><td>Non-human Categories</td><td>14.4</td><td>5.5</td><td>7.6</td><td>3.7</td><td>2.0</td><td>1.9</td><td>0.0</td></tr></tbody></table></body></html>"}, "img_idx": 0, "score": 0.8770609498023987}
{"type": "table", "bbox": [275, 652, 2151, 984], "res": {"cell_bbox": [[25.767213821411133, 131.95167541503906, 481.1529235839844, 127.69583129882812, 496.3134765625, 181.07945251464844, 25.91054916381836, 183.9181365966797], [606.5917358398438, 128.75086975097656, 678.8768920898438, 122.55741882324219, 702.5269165039062, 183.62405395507812, 622.7832641601562, 188.2447967529297], [717.8556518554688, 130.16062927246094, 789.9724731445312, 123.91118621826172, 817.4361572265625, 184.35328674316406, 737.0657348632812, 189.3145751953125], [843.794921875, 128.94720458984375, 943.266845703125, 122.94827270507812, 969.0703735351562, 182.37486267089844, 863.4022216796875, 187.62313842773438], [979.4291381835938, 129.11270141601562, 1076.857666015625, 124.0213394165039, 1097.02783203125, 184.5077362060547, 995.391845703125, 189.05625915527344], [1104.0374755859375, 132.4517059326172, 1192.4971923828125, 127.37531280517578, 1210.4520263671875, 187.9044952392578, 1119.6922607421875, 192.44375610351562], [1235.4407958984375, 133.77621459960938, 1326.2659912109375, 129.28707885742188, 1341.6649169921875, 186.97984313964844, 1248.519287109375, 191.15809631347656], [1384.5035400390625, 137.159912109375, 1474.6578369140625, 133.028076171875, 1487.0050048828125, 188.37974548339844, 1396.0975341796875, 192.315185546875], [1513.298095703125, 135.45875549316406, 1608.2806396484375, 131.95849609375, 1617.73486328125, 186.32888793945312, 1523.0372314453125, 189.69589233398438], [1637.7061767578125, 135.24085998535156, 1736.95654296875, 132.2091827392578, 1742.1314697265625, 185.72720336914062, 1645.8231201171875, 188.59326171875], [1747.7537841796875, 127.42652893066406, 1838.0472412109375, 124.79405212402344, 1839.7003173828125, 177.7703857421875, 1752.4156494140625, 180.3800811767578], [21.050643920898438, 240.36248779296875, 294.3729248046875, 238.39285278320312, 296.4740295410156, 269.3568115234375, 20.43259620666504, 271.0082702636719], [593.1830444335938, 230.90194702148438, 668.9232177734375, 228.6282958984375, 682.6663818359375, 269.87091064453125, 606.2808227539062, 271.5557556152344], [718.0437622070312, 231.25306701660156, 788.2041625976562, 229.03697204589844, 804.9703369140625, 270.0257568359375, 731.2757568359375, 271.77557373046875], [842.091552734375, 229.66925048828125, 934.3141479492188, 227.58670043945312, 949.4305419921875, 268.9272766113281, 855.5330810546875, 270.63037109375], [969.5330810546875, 228.37078857421875, 1070.541259765625, 226.54685974121094, 1085.6768798828125, 269.2552795410156, 984.2024536132812, 270.8672180175781], [1105.2615966796875, 228.6933135986328, 1200.0648193359375, 226.98834228515625, 1212.1329345703125, 269.4820556640625, 1117.6343994140625, 270.9862976074219], [1239.04443359375, 231.61328125, 1338.3199462890625, 230.00999450683594, 1349.127685546875, 268.40826416015625, 1249.0433349609375, 269.9700012207031], [1374.1553955078125, 232.9912872314453, 1470.44580078125, 231.61236572265625, 1479.2991943359375, 270.0276794433594, 1383.2818603515625, 271.3811340332031], [1499.6932373046875, 234.33421325683594, 1586.2791748046875, 233.12083435058594, 1593.165771484375, 271.49798583984375, 1507.0211181640625, 272.67327880859375], [1623.3665771484375, 233.1999969482422, 1716.650146484375, 231.97763061523438, 1720.4097900390625, 273.19940185546875, 1629.530029296875, 274.2149353027344], [1735.5201416015625, 228.474365234375, 1837.4923095703125, 226.7557373046875, 1838.655029296875, 270.905517578125, 1740.3629150390625, 272.0655822753906], [17.863170623779297, 278.35943603515625, 517.9115600585938, 277.9111633300781, 527.08544921875, 317.5084228515625, 17.705841064453125, 317.417236328125], [611.1212768554688, 275.1434631347656, 677.1602172851562, 274.4951171875, 681.1988525390625, 316.5039367675781, 614.1358642578125, 316.5248107910156], [721.1700439453125, 275.1594543457031, 790.4022216796875, 274.4006042480469, 794.378173828125, 318.0220947265625, 725.0166015625, 318.1403503417969], [848.5999755859375, 275.96435546875, 939.5963134765625, 275.0701904296875, 945.6015014648438, 316.8302001953125, 853.8727416992188, 317.030517578125], [970.0828857421875, 276.45196533203125, 1066.938720703125, 275.60552978515625, 1072.7803955078125, 316.06561279296875, 976.3108520507812, 316.2863464355469], [1092.168701171875, 276.53631591796875, 1184.397705078125, 275.5522155761719, 1188.0338134765625, 315.9232482910156, 1096.828857421875, 316.19622802734375], [1209.8043212890625, 277.09033203125, 1300.7269287109375, 276.032958984375, 1304.615234375, 316.2297668457031, 1214.5169677734375, 316.52911376953125], [1328.17626953125, 277.3403015136719, 1412.5499267578125, 276.27813720703125, 1415.533203125, 317.4580383300781, 1331.5584716796875, 317.73394775390625], [1454.0965576171875, 277.2341003417969, 1544.015380859375, 276.1946716308594, 1544.9793701171875, 317.7416076660156, 1455.261474609375, 317.999267578125], [1581.7626953125, 277.32562255859375, 1659.7890625, 276.3857421875, 1659.9771728515625, 318.347900390625, 1582.807861328125, 318.5509338378906], [1716.244140625, 273.9786071777344, 1821.685791015625, 272.6811218261719, 1821.66748046875, 317.35260009765625, 1717.6717529296875, 317.57421875]], "html": "<html><body><table><thead><tr><td>Category Label Set</td><td>0-2</td><td>3-9</td><td>10-19</td><td>20-29</td><td>30-39</td><td>40-49</td><td>50-59</td><td>60-69</td><td></td><td>over 70</td></tr></thead><tbody><tr><td>Default Label Set</td><td>30.3</td><td>35.0</td><td>29.5</td><td>16.3</td><td>13.9</td><td>18.5</td><td>19.1</td><td></td><td>16.2</td><td>10.4</td></tr><tr><td>Default Label Set + \u2018child\u2019 category</td><td>2.3</td><td>4.3</td><td>14.7</td><td>15.0</td><td>13.4</td><td></td><td>18.2</td><td>18.6</td><td>15.5</td><td>9.4</td></tr></tbody></table></body></html>"}, "img_idx": 0, "score": 0.7151411771774292}
{"type": "header", "bbox": [2127, 190, 2164, 213], "res": [{"text": "22", "confidence": 0.9992835521697998, "text_region": [[2129.0, 191.0], [2165.0, 191.0], [2165.0, 221.0], [2129.0, 221.0]]}], "img_idx": 0, "score": 0.895114004611969}
{"type": "header", "bbox": [227, 193, 1125, 224], "res": [{"text": "Learning Transferable Visual Models From Natural Language Supervision", "confidence": 0.9907500743865967, "text_region": [[220.0, 188.0], [1370.0, 188.0], [1370.0, 231.0], [220.0, 231.0]]}], "img_idx": 0, "score": 0.7054102420806885}
