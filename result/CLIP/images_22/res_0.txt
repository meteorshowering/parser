{"type": "text", "bbox": [1227, 350, 2168, 1100], "res": [{"text": "When given the combined set of labels that Google Cloud", "confidence": 0.9816644191741943, "text_region": [[1227.0, 346.0], [2172.0, 346.0], [2172.0, 393.0], [1227.0, 393.0]]}, {"text": "Vision (GCV), Amazon Rekognition and Microsoft returned", "confidence": 0.9986879229545593, "text_region": [[1231.0, 396.0], [2172.0, 396.0], [2172.0, 442.0], [1231.0, 442.0]]}, {"text": "for all the images, similar to the biases Schwemmer et al.", "confidence": 0.994172215461731, "text_region": [[1221.0, 439.0], [2172.0, 442.0], [2172.0, 488.0], [1221.0, 485.0]]}, {"text": "(2020) found in GCV systems, we found our system also", "confidence": 0.9974284172058105, "text_region": [[1227.0, 492.0], [2172.0, 492.0], [2172.0, 538.0], [1227.0, 538.0]]}, {"text": "disproportionately attached labels to do with hair and ap-", "confidence": 0.9801082015037537, "text_region": [[1224.0, 535.0], [2179.0, 535.0], [2179.0, 591.0], [1224.0, 591.0]]}, {"text": " pearance in general to women more than men. For ex-", "confidence": 0.9961472153663635, "text_region": [[1217.0, 584.0], [2175.0, 581.0], [2175.0, 637.0], [1217.0, 640.0]]}, {"text": "ample, labels such as \u201cbrown hair', \u2018blonde' and \u2018blond'", "confidence": 0.9592806696891785, "text_region": [[1224.0, 637.0], [2172.0, 630.0], [2172.0, 676.0], [1224.0, 683.0]]}, {"text": "appeared significantly more often for women. Additionally,", "confidence": 0.9989297986030579, "text_region": [[1224.0, 686.0], [2172.0, 683.0], [2172.0, 729.0], [1224.0, 733.0]]}, {"text": "CLIP attached some labels that described high status occu-", "confidence": 0.9837328791618347, "text_region": [[1224.0, 726.0], [2169.0, 729.0], [2169.0, 776.0], [1224.0, 772.0]]}, {"text": "pations disproportionately more often to men such as ^ex-", "confidence": 0.9915092587471008, "text_region": [[1227.0, 779.0], [2172.0, 779.0], [2172.0, 825.0], [1227.0, 825.0]]}, {"text": "ecutive\u2019 and \u2018doctor'. Out of the only four occupations that", "confidence": 0.9710476994514465, "text_region": [[1221.0, 818.0], [2175.0, 822.0], [2175.0, 878.0], [1221.0, 874.0]]}, {"text": " it attached more often to women, three were \u2018newscaster',", "confidence": 0.9737198352813721, "text_region": [[1217.0, 871.0], [2172.0, 871.0], [2172.0, 917.0], [1217.0, 917.0]]}, {"text": "'television presenter\u2019 and \u2018newsreader? and the fourth was", "confidence": 0.9600729942321777, "text_region": [[1217.0, 917.0], [2172.0, 917.0], [2172.0, 973.0], [1217.0, 973.0]]}, {"text": "\u2018Judge'. This is again similar to the biases found in GCV", "confidence": 0.993148922920227, "text_region": [[1217.0, 960.0], [2175.0, 964.0], [2175.0, 1020.0], [1217.0, 1016.0]]}, {"text": "and points to historical gendered differences (Schwemmer", "confidence": 0.9875409007072449, "text_region": [[1224.0, 1016.0], [2169.0, 1016.0], [2169.0, 1063.0], [1224.0, 1063.0]]}, {"text": "et al., 2020).", "confidence": 0.9900411367416382, "text_region": [[1224.0, 1063.0], [1434.0, 1063.0], [1434.0, 1109.0], [1224.0, 1109.0]]}], "img_idx": 0, "score": 0.9931354522705078}
{"type": "text", "bbox": [1227, 1692, 2169, 2369], "res": [{"text": "Design decisions at every stage of building a model impact", "confidence": 0.9961740970611572, "text_region": [[1227.0, 1690.0], [2172.0, 1690.0], [2172.0, 1736.0], [1227.0, 1736.0]]}, {"text": "how biases manifest and this is especially true for CLIP", "confidence": 0.9965242743492126, "text_region": [[1227.0, 1736.0], [2172.0, 1736.0], [2172.0, 1782.0], [1227.0, 1782.0]]}, {"text": "given the fexibility it offers. In addition to choices about", "confidence": 0.9895384311676025, "text_region": [[1224.0, 1782.0], [2175.0, 1779.0], [2175.0, 1825.0], [1224.0, 1828.0]]}, {"text": "training data and model architecture, decisions about things", "confidence": 0.99406898021698, "text_region": [[1224.0, 1828.0], [2169.0, 1832.0], [2168.0, 1878.0], [1224.0, 1874.0]]}, {"text": " like class designs and thresholding values can alter the labels", "confidence": 0.9943372011184692, "text_region": [[1217.0, 1874.0], [2172.0, 1878.0], [2172.0, 1924.0], [1217.0, 1921.0]]}, {"text": "a model outputs and as a result heighten or lower certain", "confidence": 0.9960217475891113, "text_region": [[1224.0, 1927.0], [2172.0, 1927.0], [2172.0, 1973.0], [1224.0, 1973.0]]}, {"text": "kinds of harm, such as those described by Crawford (2017).", "confidence": 0.9950408339500427, "text_region": [[1227.0, 1973.0], [2172.0, 1973.0], [2172.0, 2020.0], [1227.0, 2020.0]]}, {"text": "People designing and developing models and AI systems", "confidence": 0.9998138546943665, "text_region": [[1227.0, 2023.0], [2169.0, 2023.0], [2169.0, 2069.0], [1227.0, 2069.0]]}, {"text": "have considerable power. Decisions about things like class", "confidence": 0.990813136100769, "text_region": [[1227.0, 2069.0], [2172.0, 2069.0], [2172.0, 2115.0], [1227.0, 2115.0]]}, {"text": " design are a key determiner not only of model performance,", "confidence": 0.9858697652816772, "text_region": [[1217.0, 2109.0], [2175.0, 2112.0], [2175.0, 2168.0], [1217.0, 2165.0]]}, {"text": "but also of how and in what contexts model biases manifest.", "confidence": 0.9915423393249512, "text_region": [[1227.0, 2165.0], [2175.0, 2165.0], [2175.0, 2211.0], [1227.0, 2211.0]]}, {"text": "These experiments are not comprehensive. They illus-", "confidence": 0.9857532978057861, "text_region": [[1224.0, 2234.0], [2165.0, 2234.0], [2165.0, 2280.0], [1224.0, 2280.0]]}, {"text": "trate potential issues stemming from class design and other", "confidence": 0.9942716956138611, "text_region": [[1224.0, 2287.0], [2169.0, 2287.0], [2169.0, 2333.0], [1224.0, 2333.0]]}, {"text": "sources of bias, and are intended to spark inquiry.", "confidence": 0.9932618737220764, "text_region": [[1224.0, 2330.0], [2016.0, 2330.0], [2016.0, 2376.0], [1224.0, 2376.0]]}], "img_idx": 0, "score": 0.9931036829948425}
{"type": "text", "bbox": [1227, 1141, 2167, 1652], "res": [{"text": "Interestingly, when we lowered the threshold to 0.5% for", "confidence": 0.997596263885498, "text_region": [[1224.0, 1132.0], [2169.0, 1132.0], [2169.0, 1178.0], [1224.0, 1178.0]]}, {"text": "this set of labels, we found that the labels disproportionately", "confidence": 0.9944562911987305, "text_region": [[1224.0, 1181.0], [2172.0, 1185.0], [2172.0, 1231.0], [1224.0, 1228.0]]}, {"text": "describing men also shifted to appearance oriented words", "confidence": 0.9962831735610962, "text_region": [[1227.0, 1234.0], [2172.0, 1234.0], [2172.0, 1280.0], [1227.0, 1280.0]]}, {"text": "such as \u2018suit', \u2018tie\u2032 and \u2018necktie\u2019 (Figure 18). Many occupa-", "confidence": 0.9428259134292603, "text_region": [[1224.0, 1277.0], [2175.0, 1280.0], [2175.0, 1327.0], [1224.0, 1323.0]]}, {"text": " tion oriented words such as *military person\u2019 and \u2018executive'", "confidence": 0.9502878785133362, "text_region": [[1217.0, 1323.0], [2172.0, 1320.0], [2172.0, 1376.0], [1217.0, 1379.0]]}, {"text": "- which were not used to describe images of women at the", "confidence": 0.986125648021698, "text_region": [[1224.0, 1376.0], [2169.0, 1376.0], [2169.0, 1422.0], [1224.0, 1422.0]]}, {"text": "higher 4% threshold - were used for both men and women", "confidence": 0.9906445741653442, "text_region": [[1224.0, 1426.0], [2172.0, 1426.0], [2172.0, 1468.0], [1224.0, 1468.0]]}, {"text": "at the lower 0.5% threshold, which could have caused the", "confidence": 0.9952553510665894, "text_region": [[1224.0, 1472.0], [2169.0, 1472.0], [2169.0, 1518.0], [1224.0, 1518.0]]}, {"text": "change in labels for men. The reverse was not true. Descrip-", "confidence": 0.9838874936103821, "text_region": [[1224.0, 1515.0], [2175.0, 1521.0], [2175.0, 1568.0], [1224.0, 1561.0]]}, {"text": "tive words used to describe women were still uncommon", "confidence": 0.9918385148048401, "text_region": [[1224.0, 1564.0], [2172.0, 1571.0], [2172.0, 1614.0], [1224.0, 1607.0]]}, {"text": "amongst men.", "confidence": 0.9995327591896057, "text_region": [[1227.0, 1624.0], [1450.0, 1624.0], [1450.0, 1660.0], [1227.0, 1660.0]]}], "img_idx": 0, "score": 0.9930945038795471}
{"type": "text", "bbox": [1225, 2515, 2168, 2829], "res": [{"text": "We next sought to characterize model performance in re-", "confidence": 0.9935930967330933, "text_region": [[1227.0, 2508.0], [2169.0, 2508.0], [2169.0, 2554.0], [1227.0, 2554.0]]}, {"text": "lation to a downstream task for which there is significant", "confidence": 0.9861005544662476, "text_region": [[1227.0, 2554.0], [2172.0, 2554.0], [2172.0, 2600.0], [1227.0, 2600.0]]}, {"text": "societal sensitivity: surveillance. Our analysis aims to better", "confidence": 0.9718278050422668, "text_region": [[1224.0, 2604.0], [2169.0, 2604.0], [2169.0, 2650.0], [1224.0, 2650.0]]}, {"text": " embody the characterization approach described above and", "confidence": 0.9980707764625549, "text_region": [[1217.0, 2647.0], [2172.0, 2643.0], [2172.0, 2699.0], [1217.0, 2703.0]]}, {"text": "to help orient the research community towards the potential", "confidence": 0.9838051795959473, "text_region": [[1224.0, 2699.0], [2172.0, 2699.0], [2172.0, 2746.0], [1224.0, 2746.0]]}, {"text": "future impacts of increasingly general purpose computer", "confidence": 0.9898176193237305, "text_region": [[1224.0, 2746.0], [2165.0, 2749.0], [2165.0, 2795.0], [1224.0, 2792.0]]}, {"text": "vision models and aid the development of norms and checks", "confidence": 0.9895077347755432, "text_region": [[1231.0, 2795.0], [2165.0, 2795.0], [2165.0, 2841.0], [1231.0, 2841.0]]}], "img_idx": 0, "score": 0.9925918579101562}
{"type": "text", "bbox": [218, 1427, 1159, 1983], "res": [{"text": "We first simply looked into gender prediction performance", "confidence": 0.9842877984046936, "text_region": [[213.0, 1416.0], [1164.0, 1419.0], [1164.0, 1475.0], [213.0, 1472.0]]}, {"text": "of the model on the images of Members of Congress, in", "confidence": 0.9993442893028259, "text_region": [[220.0, 1472.0], [1164.0, 1472.0], [1164.0, 1518.0], [220.0, 1518.0]]}, {"text": " order to check to see if the model correctly recognized", "confidence": 0.9908789992332458, "text_region": [[209.0, 1515.0], [1167.0, 1511.0], [1168.0, 1567.0], [210.0, 1571.0]]}, {"text": " men as men and women as women given the image of a", "confidence": 0.976952075958252, "text_region": [[210.0, 1561.0], [1164.0, 1564.0], [1164.0, 1620.0], [209.0, 1617.0]]}, {"text": "person who appeared to be in an official setting/position of", "confidence": 0.9888089299201965, "text_region": [[216.0, 1617.0], [1164.0, 1617.0], [1164.0, 1663.0], [216.0, 1663.0]]}, {"text": "power. We found that the model got 100% accuracy on the", "confidence": 0.9828317165374756, "text_region": [[220.0, 1663.0], [1161.0, 1663.0], [1161.0, 1709.0], [220.0, 1709.0]]}, {"text": "images. This is slightly better performance than the model's", "confidence": 0.9867294430732727, "text_region": [[213.0, 1706.0], [1164.0, 1703.0], [1164.0, 1759.0], [213.0, 1762.0]]}, {"text": "performance on the FairFace dataset. We hypothesize that", "confidence": 0.995508074760437, "text_region": [[220.0, 1759.0], [1167.0, 1759.0], [1167.0, 1805.0], [220.0, 1805.0]]}, {"text": "one of the reasons for this is that all the images in the", "confidence": 0.9929667115211487, "text_region": [[216.0, 1805.0], [1164.0, 1805.0], [1164.0, 1851.0], [216.0, 1851.0]]}, {"text": "Members of Congress dataset were high-quality and clear,", "confidence": 0.9969683289527893, "text_region": [[216.0, 1855.0], [1167.0, 1855.0], [1167.0, 1901.0], [216.0, 1901.0]]}, {"text": "with the people clearly centered, unlike those in the FairFace", "confidence": 0.9948191046714783, "text_region": [[216.0, 1904.0], [1164.0, 1904.0], [1164.0, 1950.0], [216.0, 1950.0]]}, {"text": "dataset.", "confidence": 0.9999392628669739, "text_region": [[216.0, 1950.0], [346.0, 1950.0], [346.0, 1996.0], [216.0, 1996.0]]}], "img_idx": 0, "score": 0.9918491244316101}
{"type": "text", "bbox": [220, 1068, 1158, 1391], "res": [{"text": "We carried out three experiments - we tested for accuracy", "confidence": 0.9863476753234863, "text_region": [[210.0, 1056.0], [1164.0, 1059.0], [1164.0, 1115.0], [209.0, 1112.0]]}, {"text": " on gender classification and we tested for how labels were", "confidence": 0.9842066764831543, "text_region": [[213.0, 1115.0], [1164.0, 1112.0], [1164.0, 1158.0], [213.0, 1162.0]]}, {"text": "differentially distributed across two different label sets. For", "confidence": 0.9931455850601196, "text_region": [[220.0, 1162.0], [1164.0, 1162.0], [1164.0, 1204.0], [220.0, 1204.0]]}, {"text": "our first label set, we used a label set of 300 occupations and", "confidence": 0.9696143865585327, "text_region": [[220.0, 1211.0], [1161.0, 1211.0], [1161.0, 1254.0], [220.0, 1254.0]]}, {"text": "for our second label set we used a combined set of labels that", "confidence": 0.9977193474769592, "text_region": [[220.0, 1257.0], [1161.0, 1257.0], [1161.0, 1300.0], [220.0, 1300.0]]}, {"text": "Google Cloud Vision, Amazon Rekognition and Microsoft", "confidence": 0.9967857003211975, "text_region": [[220.0, 1304.0], [1161.0, 1304.0], [1161.0, 1350.0], [220.0, 1350.0]]}, {"text": " Azure Computer Vision returned for all the images.", "confidence": 0.9851263165473938, "text_region": [[213.0, 1343.0], [1041.0, 1350.0], [1041.0, 1406.0], [213.0, 1399.0]]}], "img_idx": 0, "score": 0.9908937811851501}
{"type": "text", "bbox": [219, 710, 1159, 1027], "res": [{"text": "We also carried out experiments similar to those outlined by", "confidence": 0.9904589056968689, "text_region": [[220.0, 706.0], [1161.0, 706.0], [1161.0, 752.0], [220.0, 752.0]]}, {"text": " Schwemmer et al. (2020) to test how CLIP treated images", "confidence": 0.9941906929016113, "text_region": [[210.0, 746.0], [1164.0, 749.0], [1164.0, 805.0], [209.0, 802.0]]}, {"text": "of men and women differently using images of Members", "confidence": 0.9870906472206116, "text_region": [[216.0, 802.0], [1164.0, 802.0], [1164.0, 848.0], [216.0, 848.0]]}, {"text": "of Congress. As part of these experiments, we studied", "confidence": 0.9852017760276794, "text_region": [[216.0, 851.0], [1164.0, 851.0], [1164.0, 898.0], [216.0, 898.0]]}, {"text": "how certain additional design decisions such as deciding", "confidence": 0.9990798234939575, "text_region": [[216.0, 894.0], [1164.0, 898.0], [1164.0, 944.0], [216.0, 940.0]]}, {"text": "thresholds for labels can impact the labels output by CLIP", "confidence": 0.9915969371795654, "text_region": [[213.0, 937.0], [1168.0, 941.0], [1167.0, 997.0], [213.0, 993.0]]}, {"text": "and how biases manifest.", "confidence": 0.9998486638069153, "text_region": [[216.0, 993.0], [622.0, 993.0], [622.0, 1036.0], [216.0, 1036.0]]}], "img_idx": 0, "score": 0.989475429058075}
{"type": "text", "bbox": [219, 2027, 1160, 2609], "res": [{"text": " In order to study how the biases in returned labels depend on", "confidence": 0.99742192029953, "text_region": [[213.0, 2016.0], [1161.0, 2020.0], [1161.0, 2066.0], [213.0, 2062.0]]}, {"text": "the thresholds set for label probability, we did an experiment", "confidence": 0.9930063486099243, "text_region": [[220.0, 2069.0], [1164.0, 2069.0], [1164.0, 2115.0], [220.0, 2115.0]]}, {"text": "in which we set threshold values at 0.5% and 4.0%. We", "confidence": 0.9904652237892151, "text_region": [[213.0, 2115.0], [1164.0, 2112.0], [1164.0, 2158.0], [213.0, 2162.0]]}, {"text": "found that the lower threshold led to lower quality of labels.", "confidence": 0.992207944393158, "text_region": [[220.0, 2165.0], [1164.0, 2165.0], [1164.0, 2211.0], [220.0, 2211.0]]}, {"text": "However, even the differing distributions of labels under", "confidence": 0.9874098896980286, "text_region": [[213.0, 2204.0], [1164.0, 2208.0], [1164.0, 2264.0], [213.0, 2260.0]]}, {"text": "this threshold can hold signals for bias. For example, we", "confidence": 0.9904013276100159, "text_region": [[220.0, 2264.0], [1161.0, 2264.0], [1161.0, 2307.0], [220.0, 2307.0]]}, {"text": "find that under the 0.5% threshold labels such as *nanny'", "confidence": 0.9692806601524353, "text_region": [[220.0, 2303.0], [1157.0, 2303.0], [1157.0, 2350.0], [220.0, 2350.0]]}, {"text": "and \u201chousekeeper\u2019 start appearing for women whereas labels", "confidence": 0.9757927656173706, "text_region": [[220.0, 2356.0], [1161.0, 2356.0], [1161.0, 2402.0], [220.0, 2402.0]]}, {"text": "such as \u2018prisoner\u2019 and \u2018mobster\u2019 start appearing for men.", "confidence": 0.9656559228897095, "text_region": [[216.0, 2406.0], [1167.0, 2406.0], [1167.0, 2452.0], [216.0, 2452.0]]}, {"text": "This points to gendered associations similar to those that", "confidence": 0.9917710423469543, "text_region": [[220.0, 2452.0], [1167.0, 2452.0], [1167.0, 2498.0], [220.0, 2498.0]]}, {"text": "have previously been found for occupations (Schwemmer", "confidence": 0.9985905885696411, "text_region": [[220.0, 2501.0], [1164.0, 2501.0], [1164.0, 2548.0], [220.0, 2548.0]]}, {"text": "et al., 2020) (Nosek et al., 2002) (Bolukbasi et al., 2016).", "confidence": 0.9905073642730713, "text_region": [[213.0, 2544.0], [1134.0, 2548.0], [1134.0, 2594.0], [213.0, 2590.0]]}], "img_idx": 0, "score": 0.9891233444213867}
{"type": "text", "bbox": [220, 384, 1158, 673], "res": [{"text": "The results of these probes can change based on the class", "confidence": 0.988838255405426, "text_region": [[220.0, 396.0], [1161.0, 396.0], [1161.0, 442.0], [220.0, 442.0]]}, {"text": "categories one chooses to include as well as the specific", "confidence": 0.990079939365387, "text_region": [[220.0, 446.0], [1161.0, 446.0], [1161.0, 488.0], [220.0, 488.0]]}, {"text": "language one uses to describe each class. Poor class design", "confidence": 0.9924854636192322, "text_region": [[220.0, 492.0], [1161.0, 492.0], [1161.0, 538.0], [220.0, 538.0]]}, {"text": "can lead to poor real world performance; this concern is", "confidence": 0.9940358400344849, "text_region": [[220.0, 538.0], [1164.0, 538.0], [1164.0, 584.0], [220.0, 584.0]]}, {"text": "particularly relevant to a model like CLIP, given how easily", "confidence": 0.9927186965942383, "text_region": [[220.0, 587.0], [1161.0, 587.0], [1161.0, 634.0], [220.0, 634.0]]}, {"text": " developers can design their own classes.", "confidence": 0.9942623972892761, "text_region": [[213.0, 630.0], [865.0, 634.0], [865.0, 680.0], [213.0, 676.0]]}], "img_idx": 0, "score": 0.976729691028595}
{"type": "text", "bbox": [221, 2626, 1162, 2848], "res": [{"text": "At the higher 4% threshold, the labels with the highest prob-", "confidence": 0.9778683185577393, "text_region": [[220.0, 2620.0], [1167.0, 2620.0], [1167.0, 2663.0], [220.0, 2663.0]]}, {"text": "ability across both genders include \u201clawmaker\", \u201clegislator\"", "confidence": 0.9617635011672974, "text_region": [[216.0, 2670.0], [1164.0, 2670.0], [1164.0, 2713.0], [216.0, 2713.0]]}, {"text": "and \u201ccongressman\". However, the presence of these biases", "confidence": 0.9806904792785645, "text_region": [[220.0, 2716.0], [1157.0, 2716.0], [1157.0, 2762.0], [220.0, 2762.0]]}, {"text": " amongst lower probability labels nonetheless point to larger", "confidence": 0.9902816414833069, "text_region": [[213.0, 2762.0], [1158.0, 2765.0], [1157.0, 2812.0], [213.0, 2808.0]]}, {"text": "questions about what \u2018sufficiently\u2019 safe behaviour may look", "confidence": 0.9836633205413818, "text_region": [[220.0, 2812.0], [1161.0, 2812.0], [1161.0, 2858.0], [220.0, 2858.0]]}], "img_idx": 0, "score": 0.9646106958389282}
{"type": "text", "bbox": [220, 281, 1159, 365], "res": [{"text": "images to automatically classify people along such lines", "confidence": 0.9822605848312378, "text_region": [[220.0, 277.0], [1161.0, 277.0], [1161.0, 323.0], [220.0, 323.0]]}, {"text": "(y Arcas et al., 2017).", "confidence": 0.9206410050392151, "text_region": [[210.0, 323.0], [565.0, 323.0], [565.0, 370.0], [210.0, 370.0]]}], "img_idx": 0, "score": 0.8936659693717957}
{"type": "text", "bbox": [1229, 281, 1741, 316], "res": [{"text": "like for deploying such systems.", "confidence": 0.9800320863723755, "text_region": [[1227.0, 277.0], [1746.0, 277.0], [1746.0, 323.0], [1227.0, 323.0]]}], "img_idx": 0, "score": 0.7506585121154785}
{"type": "title", "bbox": [1231, 2436, 1509, 2468], "res": [{"text": "7.2. Surveillance", "confidence": 0.9984897375106812, "text_region": [[1227.0, 2432.0], [1513.0, 2432.0], [1513.0, 2475.0], [1227.0, 2475.0]]}], "img_idx": 0, "score": 0.9479525089263916}
{"type": "header", "bbox": [2127, 191, 2163, 217], "res": [{"text": "23", "confidence": 0.9999598860740662, "text_region": [[2122.0, 188.0], [2169.0, 188.0], [2169.0, 228.0], [2122.0, 228.0]]}], "img_idx": 0, "score": 0.8994016051292419}
{"type": "header", "bbox": [292, 193, 1189, 225], "res": [{"text": "Learning Transferable Visual Models From Natural Language Supervision", "confidence": 0.9886844754219055, "text_region": [[220.0, 188.0], [1370.0, 188.0], [1370.0, 234.0], [220.0, 234.0]]}], "img_idx": 0, "score": 0.7020041942596436}
