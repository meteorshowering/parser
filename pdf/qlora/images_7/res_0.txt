{"type": "text", "bbox": [427, 1309, 2023, 1809], "res": [{"text": "Training Setup", "confidence": 0.9991922974586487, "text_region": [[429.0, 1307.0], [695.0, 1307.0], [695.0, 1353.0], [429.0, 1353.0]]}, {"text": " To avoid confounding effects from different training objectives, we perform QLoRA", "confidence": 0.9943149089813232, "text_region": [[708.0, 1307.0], [2019.0, 1307.0], [2019.0, 1353.0], [708.0, 1353.0]]}, {"text": "finetuning with cross-entropy loss (supervised learning) without reinforcement learning, even for", "confidence": 0.9938719272613525, "text_region": [[429.0, 1350.0], [2022.0, 1350.0], [2022.0, 1396.0], [429.0, 1396.0]]}, {"text": "datasets that include human judgments of different responses. For datasets that have a clear distinction", "confidence": 0.997099757194519, "text_region": [[429.0, 1393.0], [2022.0, 1393.0], [2022.0, 1439.0], [429.0, 1439.0]]}, {"text": " between instruction and response, we finetune only on the response (see ablations in Appendix B).", "confidence": 0.9860594868659973, "text_region": [[422.0, 1432.0], [2026.0, 1432.0], [2026.0, 1488.0], [422.0, 1488.0]]}, {"text": " For OASST1 and HH-RLHF, multiple responses are available. We then select the top response at", "confidence": 0.981507420539856, "text_region": [[422.0, 1472.0], [2022.0, 1475.0], [2022.0, 1531.0], [422.0, 1528.0]]}, {"text": "every level of the conversation tree and finetune on the full selected conversation, including the", "confidence": 0.9912547469139099, "text_region": [[426.0, 1525.0], [2019.0, 1521.0], [2019.0, 1567.0], [426.0, 1571.0]]}, {"text": " instructions. In all of our experiments, we use NF4 QLoRA with double quantization and paged", "confidence": 0.99363774061203, "text_region": [[419.0, 1561.0], [2022.0, 1564.0], [2022.0, 1620.0], [419.0, 1617.0]]}, {"text": " optimizers to prevent memory spikes during gradient checkpointing. We do small hyperparameter", "confidence": 0.9925539493560791, "text_region": [[422.0, 1604.0], [2022.0, 1607.0], [2022.0, 1663.0], [422.0, 1660.0]]}, {"text": " searches for the 13B and 33B LLaMA models and we find that all hyperparameter settings found", "confidence": 0.9793562293052673, "text_region": [[419.0, 1647.0], [2022.0, 1650.0], [2022.0, 1706.0], [419.0, 1703.0]]}, {"text": " at 7B generalize (including number of epochs) except learning rate and batch size. We halve the", "confidence": 0.9926426410675049, "text_region": [[419.0, 1693.0], [2026.0, 1690.0], [2026.0, 1746.0], [419.0, 1749.0]]}, {"text": "learning rate for 33B and 65B while doubling the batch size.", "confidence": 0.9936973452568054, "text_region": [[429.0, 1742.0], [1400.0, 1742.0], [1400.0, 1789.0], [429.0, 1789.0]]}], "img_idx": 0, "score": 0.9514924883842468}
{"type": "text", "bbox": [431, 2173, 1299, 2511], "res": [{"text": "Following common practice, we use the MMLU (Mas-", "confidence": 0.9776881337165833, "text_region": [[426.0, 2168.0], [1310.0, 2168.0], [1310.0, 2214.0], [426.0, 2214.0]]}, {"text": "sively Multitask Language Understanding) benchmark", "confidence": 0.9967799186706543, "text_region": [[426.0, 2208.0], [1307.0, 2208.0], [1307.0, 2264.0], [426.0, 2264.0]]}, {"text": "[24] to measure performance on a range of language un-", "confidence": 0.9950627684593201, "text_region": [[429.0, 2257.0], [1304.0, 2257.0], [1304.0, 2303.0], [429.0, 2303.0]]}, {"text": "derstanding tasks. This is a multiple-choice benchmark", "confidence": 0.9809494614601135, "text_region": [[426.0, 2300.0], [1304.0, 2300.0], [1304.0, 2346.0], [426.0, 2346.0]]}, {"text": "covering 57 tasks including elementary mathematics,", "confidence": 0.9958407282829285, "text_region": [[429.0, 2343.0], [1300.0, 2343.0], [1300.0, 2389.0], [429.0, 2389.0]]}, {"text": " US history, computer science, law, and more. We report", "confidence": 0.9757954478263855, "text_region": [[419.0, 2376.0], [1307.0, 2383.0], [1307.0, 2439.0], [419.0, 2432.0]]}, {"text": " 5-shot test accuracy.", "confidence": 0.9947195649147034, "text_region": [[423.0, 2429.0], [759.0, 2432.0], [758.0, 2478.0], [422.0, 2475.0]]}, {"text": "We also test generative language capabilities through", "confidence": 0.986333966255188, "text_region": [[419.0, 2488.0], [1307.0, 2492.0], [1307.0, 2548.0], [419.0, 2544.0]]}], "img_idx": 0, "score": 0.9388942122459412}
{"type": "text", "bbox": [1334, 2188, 2015, 2298], "res": [{"text": " Table 5: MMLU 5-shot test results for different", "confidence": 0.9806218147277832, "text_region": [[1324.0, 2181.0], [2022.0, 2181.0], [2022.0, 2224.0], [1324.0, 2224.0]]}, {"text": " sizes of LLaMA finetuned on the corresponding", "confidence": 0.9896949529647827, "text_region": [[1327.0, 2221.0], [2026.0, 2221.0], [2026.0, 2267.0], [1327.0, 2267.0]]}, {"text": "datasets using QLoRA.", "confidence": 0.9997392296791077, "text_region": [[1330.0, 2260.0], [1670.0, 2260.0], [1670.0, 2307.0], [1330.0, 2307.0]]}], "img_idx": 0, "score": 0.729087233543396}
{"type": "text", "bbox": [424, 2808, 2016, 2888], "res": [{"text": " commonly accepted protocol in the literature. We de-", "confidence": 0.9873648881912231, "text_region": [[419.0, 2756.0], [1310.0, 2752.0], [1311.0, 2808.0], [419.0, 2812.0]]}, {"text": " scribe below our proposed setup, using nucleus sampling with p = 0.9 and temperature 0.7 in all", "confidence": 0.9887722134590149, "text_region": [[422.0, 2805.0], [2019.0, 2805.0], [2019.0, 2851.0], [422.0, 2851.0]]}, {"text": "cases.", "confidence": 0.9996550679206848, "text_region": [[429.0, 2854.0], [526.0, 2854.0], [526.0, 2891.0], [429.0, 2891.0]]}], "img_idx": 0, "score": 0.7150776386260986}
{"type": "title", "bbox": [431, 2113, 708, 2144], "res": [{"text": "5.2Evaluation", "confidence": 0.9999148845672607, "text_region": [[426.0, 2109.0], [715.0, 2109.0], [715.0, 2155.0], [426.0, 2155.0]]}], "img_idx": 0, "score": 0.9509349465370178}
{"type": "title", "bbox": [430, 931, 857, 966], "res": [{"text": " 5.1 Experimental setup", "confidence": 0.9655575752258301, "text_region": [[423.0, 920.0], [862.0, 928.0], [861.0, 974.0], [422.0, 967.0]]}], "img_idx": 0, "score": 0.889198899269104}
{"type": "title", "bbox": [432, 807, 2017, 892], "res": [{"text": "on a challenging Natural Language Understanding benchmark (MMLU) and develop new methods", "confidence": 0.9951967000961304, "text_region": [[426.0, 805.0], [2019.0, 805.0], [2019.0, 851.0], [426.0, 851.0]]}, {"text": "for real-world chatbot performance evaluation.", "confidence": 0.9985978603363037, "text_region": [[426.0, 848.0], [1177.0, 848.0], [1177.0, 894.0], [426.0, 894.0]]}], "img_idx": 0, "score": 0.887075662612915}
{"type": "table", "bbox": [1338, 2330, 2027, 2730], "res": {"cell_bbox": [[6.721248626708984, 3.3026721477508545, 458.6073913574219, 3.515872001647949, 455.352783203125, 48.75617980957031, 6.450387954711914, 47.414703369140625], [11.625640869140625, 42.57439422607422, 649.1807861328125, 43.32571029663086, 648.5670776367188, 98.27013397216797, 11.215422630310059, 97.39866638183594], [18.034942626953125, 87.11329650878906, 678.7733764648438, 85.80580139160156, 678.3558349609375, 388.2397766113281, 17.439529418945312, 388.33258056640625]], "html": "<html><body><table><tbody><tr><td>Dataset 7B 13B</td></tr><tr><td>33B 65B LLaMA no tuning 35.1 46.9 57.8 63.4</td></tr><tr><td>Self-Instruct 36.4 33.3 53.0 56.7 Longform 32.1 43.2 56.6 59.7 Chip2 34.5 41.6 53.6 59.8 HH-RLHF 34.9 44.6 55.8 60.1 Unnatural Instruct 41.9 48.1 57.3 61.3 Guanaco (OASST1) 36.6 46.4 57.0 62.2 Alpaca 38.8 47.8 57.3 62.5 FLAN v2 44.5 51.4 59.2 63.9</td></tr></tbody></table></body></html>"}, "img_idx": 0, "score": 0.9581593871116638}
{"type": "table", "bbox": [419, 446, 2031, 726], "res": {"cell_bbox": [[63.86628723144531, 46.32758712768555, 294.8694763183594, 46.835391998291016, 296.5322265625, 81.30574035644531, 62.36123275756836, 79.41818237304688], [596.3528442382812, 13.550088882446289, 1159.016357421875, 13.854891777038574, 1162.333984375, 45.64707565307617, 600.4640502929688, 45.18339157104492], [1497.64404296875, 52.09038543701172, 1582.3544921875, 52.69697189331055, 1582.0595703125, 79.62206268310547, 1496.1571044921875, 78.62826538085938], [291.8912048339844, 55.31178283691406, 446.9074401855469, 54.85728454589844, 452.987548828125, 94.09256744384766, 295.7320861816406, 95.37097930908203], [633.2401733398438, 54.63536071777344, 756.3543701171875, 54.446495056152344, 766.3087768554688, 91.91986083984375, 645.3218994140625, 92.25125122070312], [901.2584838867188, 54.10038757324219, 1046.739013671875, 53.91416549682617, 1051.8436279296875, 89.79933166503906, 909.9951782226562, 89.85078430175781], [1198.7786865234375, 50.34673309326172, 1383.824462890625, 50.322139739990234, 1385.3433837890625, 92.05561065673828, 1203.563720703125, 92.086669921875], [314.6549377441406, 89.151611328125, 446.5941467285156, 90.12994384765625, 444.9287109375, 126.54254150390625, 312.1124572753906, 125.87032318115234], [446.6793212890625, 93.93541717529297, 538.752685546875, 93.90762329101562, 542.0175170898438, 129.98324584960938, 447.6348876953125, 130.36984252929688], [601.4381713867188, 91.44990539550781, 701.1698608398438, 91.4914321899414, 705.2313842773438, 128.72801208496094, 607.3179321289062, 129.07223510742188], [740.4633178710938, 91.50811767578125, 842.1861572265625, 91.45552825927734, 845.3109741210938, 128.9759063720703, 743.3744506835938, 129.45223999023438], [905.9575805664062, 91.91462707519531, 1004.36376953125, 91.88140106201172, 1006.5848999023438, 130.330810546875, 909.6030883789062, 130.651611328125], [1048.4334716796875, 90.0261001586914, 1153.5457763671875, 90.10104370117188, 1154.03369140625, 130.41424560546875, 1049.5220947265625, 130.5380401611328], [1218.354248046875, 90.2366943359375, 1316.9012451171875, 90.3461685180664, 1318.1072998046875, 129.2126922607422, 1221.2244873046875, 129.40211486816406], [1347.9736328125, 90.31237030029297, 1440.7119140625, 90.64126586914062, 1442.5546875, 130.9519805908203, 1351.05859375, 131.11050415039062], [52.7567024230957, 150.9825897216797, 198.81927490234375, 151.53103637695312, 195.19735717773438, 180.77926635742188, 50.65190505981445, 180.30763244628906], [301.7518615722656, 149.89059448242188, 366.86492919921875, 150.35107421875, 368.5092468261719, 179.733642578125, 302.9834289550781, 179.46792602539062], [456.1298828125, 150.39361572265625, 537.8755493164062, 150.70758056640625, 539.8557739257812, 183.95985412597656, 456.89447021484375, 183.84591674804688], [621.688720703125, 149.73597717285156, 677.352294921875, 150.09034729003906, 683.4158325195312, 181.48313903808594, 626.4381103515625, 181.3619384765625], [745.655029296875, 149.17062377929688, 840.9415283203125, 149.403564453125, 845.531982421875, 182.56455993652344, 749.072509765625, 182.57713317871094], [909.0927124023438, 148.6497802734375, 975.8705444335938, 149.0400390625, 980.7763061523438, 182.37403869628906, 913.573486328125, 182.26800537109375], [1053.4012451171875, 147.91220092773438, 1131.6197509765625, 148.2778778076172, 1134.8436279296875, 181.628662109375, 1056.2548828125, 181.50949096679688], [1205.5604248046875, 147.4232635498047, 1267.212890625, 147.79324340820312, 1269.4852294921875, 180.64108276367188, 1208.6448974609375, 180.5330810546875], [1360.8819580078125, 148.0516357421875, 1430.842529296875, 148.61929321289062, 1431.468017578125, 181.81068420410156, 1361.4503173828125, 181.5508575439453], [1498.225830078125, 147.52821350097656, 1567.5433349609375, 147.85433959960938, 1567.2110595703125, 182.66973876953125, 1497.683349609375, 182.47427368164062], [50.90584945678711, 186.25643920898438, 194.20533752441406, 186.6331787109375, 194.21630859375, 217.48927307128906, 50.68260955810547, 217.1436309814453], [295.2194519042969, 184.87591552734375, 357.9972229003906, 185.43421936035156, 360.0553283691406, 215.78778076171875, 296.5271911621094, 215.48208618164062], [452.1554260253906, 185.1792755126953, 530.1206665039062, 185.6742401123047, 529.5736694335938, 217.3365020751953, 452.033935546875, 217.1526336669922], [620.141845703125, 185.22039794921875, 673.1611938476562, 185.7307586669922, 676.7582397460938, 216.33322143554688, 623.193603515625, 216.22474670410156], [745.7178955078125, 184.7765655517578, 835.474609375, 185.180419921875, 836.1273803710938, 218.50018310546875, 746.5560913085938, 218.4050750732422], [912.4711303710938, 184.92503356933594, 976.6666870117188, 185.32298278808594, 978.994384765625, 217.84194946289062, 914.955078125, 217.7761688232422], [1050.3238525390625, 184.66253662109375, 1126.323486328125, 184.99078369140625, 1127.125244140625, 218.11654663085938, 1051.6947021484375, 218.0110321044922], [1204.3458251953125, 184.76612854003906, 1267.3258056640625, 185.04432678222656, 1268.416015625, 216.5631103515625, 1206.420166015625, 216.54173278808594], [1356.7100830078125, 185.66407775878906, 1429.4583740234375, 186.00592041015625, 1429.27392578125, 217.60003662109375, 1356.7440185546875, 217.4632568359375], [1501.904541015625, 185.35885620117188, 1570.7635498046875, 185.58074951171875, 1570.3798828125, 218.42686462402344, 1501.2061767578125, 218.30709838867188], [37.77367401123047, 222.2517547607422, 242.62367248535156, 222.7833709716797, 243.34788513183594, 257.87994384765625, 37.35218811035156, 257.5147399902344], [285.0242919921875, 221.89254760742188, 366.4104919433594, 222.5467529296875, 367.7481689453125, 256.896484375, 284.99237060546875, 256.52130126953125], [443.3090515136719, 222.37828063964844, 532.0609741210938, 222.73965454101562, 531.3082275390625, 257.7458801269531, 442.06890869140625, 257.5593566894531], [609.6370849609375, 222.20289611816406, 672.2568969726562, 222.51927185058594, 675.2424926757812, 258.1390380859375, 612.3245239257812, 258.0314636230469], [743.2526245117188, 222.34437561035156, 833.1758422851562, 222.58407592773438, 834.4254150390625, 258.93792724609375, 744.14990234375, 258.8437805175781], [895.1986694335938, 222.244140625, 967.5861206054688, 222.44654846191406, 969.7658081054688, 260.3363037109375, 897.968505859375, 260.2851867675781], [1039.14013671875, 222.68296813964844, 1115.5625, 222.8207550048828, 1117.464111328125, 259.8652648925781, 1041.2860107421875, 259.8082275390625], [1195.564697265625, 222.50477600097656, 1261.31396484375, 222.55459594726562, 1261.78076171875, 258.1914978027344, 1196.74853515625, 258.18560791015625], [1338.7525634765625, 223.33226013183594, 1419.2332763671875, 223.4203643798828, 1419.73828125, 257.7325439453125, 1339.4674072265625, 257.6804504394531], [1500.9901123046875, 222.61216735839844, 1570.572265625, 222.70150756835938, 1570.6038818359375, 257.3378601074219, 1501.441162109375, 257.22314453125]], "html": "<html><body><table><thead><tr><td rowspan=\"3\">LLaMA Size</td><td colspan=\"8\">Mean 5-shot MMLU Accuracy</td><td rowspan=\"3\">Mean</td></tr><tr><td colspan=\"2\">7B</td><td colspan=\"2\">13B</td><td colspan=\"2\">33B</td><td colspan=\"2\">65B</td></tr><tr><td>Alpaca</td><td>FLAN v2</td><td> Alpaca</td><td>FLAN v2</td><td>Alpaca</td><td>FLAN v2</td><td>Alpaca</td><td>FLAN v2</td></tr></thead><tbody><tr><td>Dataset BFloat16</td><td>38.4</td><td>45.6</td><td>47.2</td><td>50.6</td><td>57.7</td><td>60.5</td><td>61.8</td><td>62.5</td><td>53.0</td></tr><tr><td>Float4</td><td>37.2</td><td>44.0</td><td>47.3</td><td>50.0</td><td>55.9</td><td>58.5</td><td>61.3</td><td>63.3</td><td>52.2</td></tr><tr><td>NFloat4 + DQ</td><td>39.0</td><td>44.5</td><td>47.5</td><td>50.7</td><td>57.3</td><td>59.2</td><td>61.8</td><td>63.9</td><td>53.1</td></tr></tbody></table></body></html>"}, "img_idx": 0, "score": 0.9545295238494873}
{"type": "table_caption", "bbox": [434, 318, 2020, 429], "res": [{"text": "Table 4: Mean 5-shot MMLU test accuracy for LLaMA 7-65B models finetuned with adapters on Alpaca and", "confidence": 0.9907010793685913, "text_region": [[426.0, 314.0], [2019.0, 314.0], [2019.0, 356.0], [426.0, 356.0]]}, {"text": "FLAN v2 for different data types. Overall, NF4 with double quantization (DQ) matches BFloat16 performance,", "confidence": 0.9871839880943298, "text_region": [[426.0, 353.0], [2026.0, 353.0], [2026.0, 399.0], [426.0, 399.0]]}, {"text": "while FP4 is consistently one percentage point behind both.", "confidence": 0.9951146245002747, "text_region": [[429.0, 393.0], [1287.0, 393.0], [1287.0, 439.0], [429.0, 439.0]]}], "img_idx": 0, "score": 0.8462451696395874}
{"type": "footer", "bbox": [1213, 2974, 1240, 3000], "res": [], "img_idx": 0, "score": 0.5837329626083374}
